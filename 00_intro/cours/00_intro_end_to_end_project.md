<center><h1> Chapitre d'introduction : Projet Data et concepts utiles</h1></center>
<p align="center">
<img src="https://github.com/Roulitoo/cours_iae/blob/master/00_intro/img/Logo_IAE_horizontal.png" alt="Logo IAE.png" style="width:200px;"/>
</p>

#### Table of Contents

[1. Mener un projet data](#1-etapes-dun-projet-data) `<br>`
&nbsp;&nbsp;&nbsp;&nbsp;[1.1 Bien d√©finir le probl√®me](#11-bien-d%C3%A9finir-le-probl%C3%A8me) `<br>`
&nbsp;&nbsp;&nbsp;&nbsp;[1.2 Trouver les donn√©es](#12-trouver-les-donn%C3%A9es) `<br>`
&nbsp;&nbsp;&nbsp;&nbsp;[1.3 Explorer les donn√©es](#13-explorer-les-donn%C3%A9es) `<br>`
&nbsp;&nbsp;&nbsp;&nbsp;[1.4 Pr√©parer le dataset](#14-pr%C3%A9parer-le-dataset) `<br>`
&nbsp;&nbsp;&nbsp;&nbsp;[1.5 Explorer vos mod√®les](#15-explorer-des-mod%C3%A8les-et-d%C3%A9terminer-une-short-list) `<br>`
&nbsp;&nbsp;&nbsp;&nbsp;[1.6 Tuner les mod√®les](#16-tuner-les-mod%C3%A8les) `<br>`
&nbsp;&nbsp;&nbsp;&nbsp;[1.7 Pr√©senter votre solution](#17-pr%C3%A9senter-votre-solution) `<br>`
&nbsp;&nbsp;&nbsp;&nbsp;[1.8 Automatiser,monitorer,maintenir](#18-automatiser-votre-mod%C3%A8le-monitorer-votre-mod%C3%A8le-et-le-maintenir) `<br>`

[2. Liste de concept utile](#-2-liste-de-concept-utile-) `<br>`
&nbsp;&nbsp;&nbsp;&nbsp;[2.1 Imbalanced dataset](#21-imbalanced-dataset) `<br>`
&nbsp;&nbsp;&nbsp;&nbsp;[2.2 Feature scaling](#22-features-scaling) `<br>`
&nbsp;&nbsp;&nbsp;&nbsp;[2.3 Gradient descent](#23-gradient-descent) `<br>`
&nbsp;&nbsp;&nbsp;&nbsp;[2.4 Loss or metric function](#24-loss-function-or-metric-function) `<br>`
&nbsp;&nbsp;&nbsp;&nbsp;[2.5 Hyperparam√®tres](#25-hyperpam%C3%A8tre) `<br>`
&nbsp;&nbsp;&nbsp;&nbsp;[2.6 Grid search](#26-grid-search) `<br>`
&nbsp;&nbsp;&nbsp;&nbsp;[2.7 Learning curve](#27-learning-curve) `<br>`
&nbsp;&nbsp;&nbsp;&nbsp;[2.8 Computational complexity](#28-computational-complexity) `<br>`
&nbsp;&nbsp;&nbsp;&nbsp;[2.9 Python environnement virtuel](#29-Python-environnement-virtuel) `<br>`

## 1-Etapes d'un projet Data

## 1.1-Bien d√©finir le probl√®me

Bien que vous ayez un profil technique, la gestion de projets fera partie de votre m√©tier.

Chaque projet doit d'avoir un probl√®me bien cadr√© sinon vous allez dans le mur!
Si vous n'√™tes pas en mesure de d√©finir le probl√®me, vous ne saurez pas √† quoi r√©pondre et donc vous ne pourrez rien d√©velopper ou alors vous r√©pondrez √† c√¥t√© dans **90%** des cas!

Pour ce faire vous pouvez suivre les recommandations suivantes :

##### Explorez la probl√©matique qui vous est pos√©e.

Quel est le probl√®me?
Pourquoi le probl√®me existe, qu'est-ce que cela engendre?
Quelles sont les solutions pour y r√©pondre aujourd'hui?
Mesure-t-on le probl√®me aujourd'hui?
*S'il n'y a aucune donn√©es pour le mesurer, il sera compliqu√© pour vous de prouver a post√©riori que votre projet am√©liore quoi que ce soit.*
Qui est impact√© par ce probl√®me?

##### Echangez, parler, identifier les personnes qui pourront r√©pondre √† vos questions

Quand on d√©bute on peut avoir envie d'aller directement √† la solution mais d√©finir le probl√®me est g√©n√©ralement le fondement du projet.
Sauf si vous √™tes d√©ja expert dans le domaine d'application, pensez √† interroger les personnes qui gravitent autour du probl√®me et ne vous lancez pas directement dans le traitement des donn√©es!

Ce seront vos interpr√©teurs cl√©s et ils vous suivront le long du projet. **Plus t√¥t vous int√©grerez les utilisateurs finaux de votre projet plus vite vous verrez si vous √™tes √©loign√©s ou non de leurs attentes**

> A l'image d'un architecte, plus les plans de votre projet seront pr√©cis plus il sera facile de le d√©velopper apr√®s.
> Un probl√®me clairement sp√©cifi√© vous permettra de mieux d√©couper votre travail et vous gagnerez du temps par la suite

##### Synth√©tiser votre travail souvent

A la fin de l'√©tape de d√©finition du probl√®me vous devriez √™tre capable de :

- D√©finir le **PROBLEME** que vous r√©glerez et le **BESOIN** auquel il r√©pond
- Mesurer avec quantitativement/qualitativement le probl√®me
- Expliquer votre solution et ses impactes
- D√©couper votre solution en plusieurs √©tapes

`<u>`Synth√©tiser ces points dans un document et pr√©senter-le `</u>`

##### Commencez petit

Parfois, il vaut mieux prototyper rapidement et pr√©senter votre solution avant de vous lancer dans de grands d√©veloppements.
Un prototype rapide √† d√©velopper  qu'on peut tester rapidement restera mieux qu'un projet de 2ans o√π on d√©veloppe dans son coin sans avoir de retour(parfois le pire est de travailler longtemps de son cot√© et se rendre compte que notre travail ne convient pas)

## 1.2-Trouver les donn√©es

Maintenant que vous avez un 'plan', vous savez comment r√©pondre th√©oriquement au probl√®me mais il va falloir se confronter √† la r√©alit√©.

Vous allez devoir trouver les donn√©es dont vous avez besoin pour r√©pondre √† votre probl√©matique:

**1** Lister intuitivement les donn√©es dont vous avez besoin `<br>`
**2** Trouver un interlocuteur ou un document vous expliquant o√π sont les donn√©es/ comment elles sont g√©n√©r√©es `<br>`
**3** Cr√©er vous un nouvel espace de travail( **un espace par projet**)`<br>`
**4** V√©rifier les **obligations l√©gales relatives √† vos donn√©es** (RGDP, Techniques, fuites de donn√©es, ...)`<br>`
**5** Demander des autorisations (si besoin)`<br>`
**6** Commencer √† regarder le type des donn√©es dont vous avez besoin (Image, texte, tabulaire, temporelle, g√©ographique,...)`<br>`
**7** Cr√©er un **code automatisable** pour r√©cup√©rer vos donn√©es `<br>`
**8** Structurer votre jeu de donn√©es pour que ce soit simple par la suite :

- Format des donn√©es
- Nom des colonnes
- Restriction sur votre p√©rim√®tre

## 1.3-Explorer les donn√©es

Dans cette partie vous allez essayer de faire ressortir les *insights* de vos donn√©es
üí° **Pensez automatisation, si vous rajoutez des nouvelles donn√©es vous ne devez pas recoder l'analyse**

**1** Cr√©er une copie de votre dataset pour travailler dessus (diminuer le taille s'il est trop volumineux)
`<br>`
`<br>`
**2** Pour de l'exploration jupyter notebook est tr√®s bien! (on l'oubliera pour le passage en production)`<br>`
**3** Analyser vos donn√©es de fa√ßon descriptive.

> Un conseil, regarder du cot√© de [html report pandas](https://github.com/ydataai/pandas-profiling)

**4** Modifier le type de vos donn√©es si n√©cessaire `<br>`
**5** Pour une analyse supervis√©e, identifier la variable cible (target)`<br>`
**6** Visualiser les donn√©es `<br>`
**7** Etudier les corr√©lations `<br>`
**8** R√©fl√©chir √† comment r√©soudre le probl√®me en tant qu'humain sans coder&nbsp;&nbsp;&nbsp;Quelles informations utiliseriez-vous? Comment le feriez-vous?&nbsp;&nbsp;&nbsp;Apr√®s l'avoir fait, essayer de transposer votre approche en code**9** Commencer le *feature engineering* pour cr√©er des nouvelles features `<br>`
**10** Retourner √† l'√©tape 2 s'il manque des donn√©es

> Pensez √† Documenter vos trouvailles, documenter, documenter, documenter!

## 1.4-Pr√©parer le dataset

üí°Travailler sur une copie du dataset
üí°Ecrivez des functions et pas du code non r√©utilisable

### Plan pour pr√©parer son dataset

- 1) **Data cleaning** (outliers, NA value, ...)
- 2) **Feature selection**(si besoin)

  - Etudes des corr√©lations
  - Variables d'importances
  - R√©gression p√©nalis√©e
  - Stats descriptives
- 3) **Feature engineering** adatp√© √† vos besoins

  - Discr√©tiser vos donn√©es continues
  - Recoder variables cat√©gorielles
  - Ajouter des transformations de features
  - Agr√©ger des features
- 4) **Feature scaling**

  - Standardiser ou normaliser vos features

> Ce [bouquin](https://www.oreilly.com/library/view/feature-engineering-for/9781491953235/) est pas mal si ca vous int√©resse d'en savoir plus `<br>`
> Un site pour la [Feature selection](https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/])

## 1.5-Explorer des mod√®les et d√©terminer une short-list

**1)** Entrainer des mod√®les avec les hyperparam√®tres par d√©faut
&nbsp;&nbsp;&nbsp; *Des mod√®les avec des paradigmes diff√©rents (regressions, arbres, svm, neural net, xgboost,...*

**2** Mesurer les performances de chaque mod√®le
&nbsp;&nbsp;&nbsp;*Utiliser une cross-validation avec n-fold*

**3** Analyser les variables d'importances pour chaque mod√®le

**4** Analyser les erreurs du mod√®le

**5** R√©aliser une liste des features pertinents

**6** Essayer de changer d'am√©liorer rapidement vos pr√©c√©dents mod√®les

**7** Garder une liste des 3 meilleurs mod√®les

## 1.6-Tuner les mod√®les

üèÅ Vous allez maintenant utiliser l'ENSEMBLE de vos donn√©es pour obtenir le meilleur mod√®le possible

**1** Tunez vos mod√®les en utilisant une cross validation

- Par exp√©rience, je vous conseille de traiter votre feature engineering comme un hyperparam√®tre.
  Surtout si vous n'√™tes pas s√ªr de votre strat√©gie (ie, imputation NA, r√©unification Data, ...)
- Random grid, search, bayesian grid search

**2** Si vos mod√®les offres des performances faibles, testez les [mod√®les ensemblistes](https://scikit-learn.org/stable/modules/ensemble.html)

**3** Quand votre mod√®le est suffisament performant sur le **training set**, mesurer sa performance avec le **test set**

## 1.7-Pr√©senter votre solution

**1** Documentez votre projet
&nbsp;&nbsp;&nbsp;*Pensez bien √† expliquer les choix que vous avez faits*

**2** Cr√©er une pr√©sentation sympa (pas de word SVP)
&nbsp;&nbsp;&nbsp;*Mettez en avant les informations importantes*

**3** Expliquer concr√®tement comment votre projet r√©pond au besoin business (besoin de d√©part)

**4** Pensez √† comment vous allez vendre votre projet!
&nbsp;&nbsp;&nbsp;*Si vous n'√™tes pas dans une entreprise tech, il sera parfois compliqu√© de prouver que votre mod√®le est utile.*`<br>`
&nbsp;&nbsp;&nbsp;*Faites de la com, soyez imaginatif*

## 1.8-Automatiser votre mod√®le, monitorer votre mod√®le et le maintenir

**1** Pr√©parer votre code pour passer en production

**2** Pr√©parer un monitoring de votre code

- Suivre la performance de votre mod√®le (KPI)
- Suivre que votre mod√®le s'excute bien
- V√©rifier que le mod√®le ne se d√©grade pas
- Mesurer qu'il n'y a pas de d√©rive sur vos donn√©es

**3** Faites r√©guli√®rement des points avec le business pour prouver que votre solution am√©liore la situation

<center><h1> 2-Liste de concept utile </h1></center>

## 2.1-Imbalanced dataset

Le cas le plus commun de donn√©es d√©s√©quilibr√©es est une classification binaire.

Prenons l'exemple d'une fraude √† la carte bancaire.
Nous avons un data set contenant 1 million d'op√©rations bancaires. La fraude √©tant un √©l√©ment rare (heuresement) notre data set ne contient que 10 000 fraudes pour 990 000 non fraudes.

Si nous entrainons un mod√®le de machine learning pour une classification binaire sur ce projet, il sera incapable d'apprendre ce qu'est une fraude car nous ne lui pr√©senterons pas suffisamment d'exemple pour qu'il arrive √† d√©finir une fraude.

Imaginons tout de m√™me que nous entrainions une rehression logistique sur ce dataset.**Le mod√®le donne une accuracy de 89%**

> Est-ce une bonne nouvelle, le mod√®le est-il pertinent?

On aurait tendance √† dire oui car 89% de bonne pr√©diction semble √™tre une valeur √©lev√©e mais 89% est plus faible qu'une pr√©diction na√Øve...

Un algo qui dirait syst√©matiquement qu'une op√©ration n'est pas une fraude aurait raison √† 99% du temps 99000/1000000.

Si vous √™tes confront√© √† ce genre de probl√®me, vous pouvez utiliser les m√©thodes suivantes :

- **Upsampling** : Augmenter l'√©v√©nement rare avec un tirage al√©atoire avec replacement
- **Downsampling** : Diminuer l'√©v√©nement non rare en retirant des cas
- **Oversampling** : Algorithme ROSE ou SMOTE cr√©ant artificiellement de nouveaux cas rares

> Lien pour smote et rose https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/

## 2.2-Features scaling

Le scaling feature (mettre vos donn√©es √† la m√™me √©chelle) permet d'exprimer diff√©rentes features avec diff√©rentes grandeurs num√©riques dans une m√™me unit√©s.

Il exite 2 grandes familles pour le feature scaling :

- La normalisation
- La standardisation

Les 2 permettent d'exprimer les colonnes num√©riques dans une m√™me unit√©s, am√©liorer le temps de calcul des mod√®les et pour certain mod√®le donner de meilleures performances.

### Normalisation

La normalisation est le fait de transformation vos features dans **une √©chelle [0,1]**. On l'appelle parfois *min-max scaling*.
Sa formule est la suivante

$X_{norm} = \frac{X-X_{min}}{X_{max}-X_{min}}$

```python
from sklearn.preprocessing import MinMaxScaler
#Exmple
data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]
scaler = MinMaxScaler() 
print(scaler.fit_transform(data))
```

### Standardisation

La standardisation est une technique qui permet quant √† elle de transformer nos colonnes en variable avec une **moyenne de 0 et un √©cart type de 1.**
Les colonnes transform√©es auront donc les m√™mes param√®tres de distribution.
La standardisation pr√©sente des avantages quand il existe des outliers, comme on utilise pas la valeur Min et Max, la technique y est moins sensible!

$z = \frac{X-\mu}{\sigma}$

```python
from sklearn.preprocessing import StandardScaler
data = [[4, 8], [-5, 25], [4, 1], [9, 2.5]]
scaler = StandardScaler()
print(scaler.fit_transform(data))

```

> Article int√©ressant : https://towardsdatascience.com/normalization-vs-standardization-quantitative-analysis-a91e8a79cebf

## 2.3-Gradient Descent

Quand vous calculez les param√®tres de votre mod√®le vous avez 2 possibilit√©s :

- Utiliser une r√©solution math√©matique pour obtenir la solution optimale (exemple, r√©solution MCO reg lin√©aire)
- Utiliser une r√©solution d'optimisation successive appell√©e **Descent de Gradient** qui va chercher it√©rativement les param√®tres qui minisent la fonction de co√ªt du mod√®le

> Plus d'informations ici https://developers.google.com/machine-learning/crash-course/reducing-loss/an-iterative-approach

Concr√®tement vous commencez avec un param√®tr $\theta$ donn√© et vous allez le faire varier it√©rativement en fonction de la valeur de sa d√©riv√©e.
On peut l'observer graphiquement sur le graphique N¬∞1

`<u>`Graphique N¬∞1 :Descente de gradient `</u>`

<img src="https://github.com/Roulitoo/cours_iae/blob/master/00_intro/img/descente_gradient_1.png" alt="fig_1_descente_gradient.png" style="width:600px;"/>

Chaque point rouge repr√©sente une it√©ration de descente de gradient et converge vers le minimum global de la fonction de perte.
Nous obtenons en ce point pour un param√®tre $\theta$ dont la valeur minimise notre fonction de perte.

`<u>`Graphique N¬∞2 :Descente de gradient, learning rate trop faible `</u>`

<img src="https://github.com/Roulitoo/cours_iae/blob/master/00_intro/img/descente_gradient_2.png" alt="fig_2_descente_gradient.png" style="width:600px;"/>

Il est important que la taille du 'saut' de mise √† jour de la valeur de votre param√®tre $\theta$ ne soit pas trop faible.
On appellera le param√®tre qui contr√¥le le 'saut' **LEARNING RATE**.
Si celui-ci est trop faible vos 'sauts' seront petits, il faudra beaucoup d'it√©rations avant de trouver le param√®tre optimal.

`<u>`Graphique N¬∞3 :Descente de gradient, learning rate trop haut `</u>`

<img src="https://github.com/Roulitoo/cours_iae/blob/master/00_intro/img/descente_gradient_3.png" alt="fig_3_descente_gradient.png" style="width:600px;"/>

A l'inverse si le *LEARNING RATE* est trop √©lev√© vous pourriez ne jamais trouver l'optimal de votre fonction.
Le calcul divergera et ne trouvera jamais de minimum local.

Un peu de math pour comprendre la descente de gradientüòÄ.
C'est un concept fondamental pour les algorithmes de machine learning!!

Exemple de descente de gradient avec **fonction de co√ªt MSE** pour un mod√®le lin√©aire:

On d√©finit une fonction lin√©aire avec un vecteur de param√®tre $\theta$
$\widehat{y} = \theta_0 + \theta_1x1+...+\theta_nxn$

o√π  :

- $\theta_0 : Biais\space du\space modele $
- $\theta_n : Param√®tre \space du \space mod√®le$
- $\widehat{y} : Valeur\space pr√©dite$
- $n : Nombre \space de \space features$

Au format vectoriel nous avons l'√©quation suivante :

$\widehat{y} = h_\theta(x) = \theta.X$

On d√©finit la fonction de perte de ce mod√®le comme :

$MSE(X, h_\theta) = \frac{1}{N}\sum_{i=1}^N (y_i-\widehat{y_i})¬≤$

Pour impl√©menter la descente de gradient, vous devez calculer le gradient de la fonction de co√ªt MSE en fonction de ses param√®tres $\theta$
On doit donc calculer toutes les d√©riv√©es partielles de la fonction MSE

$\frac{\partial}{\partial \theta_j} MSE(\theta) = \frac{2}{N}\sum_{i=1}^N (\theta^Tx^{(i)}-y^{(i)})x^{(i)}_j$

ou au format vectoriel

$$
\nabla_\theta MSE(\theta) = \begin{pmatrix}  \frac{\partial}{\partial \theta_0} \\ \frac{\partial}{\partial \theta_1} \\ . \\frac{\partial}{\partial \theta_n}  \end{pmatrix} =\frac{2}{N}X^T (X\theta-y)
$$

Une fois que vous avez le vecteur de descente de gradient, vous devez simplement mettre √† jour vos param√®tres $\theta$ jusqu'√† atteindre le minimum de votre fonction.

$\theta^{(next)} = \theta - \eta\nabla_\theta MSE(\theta)$

#### Exemple descente de gradient

Un exemple en dimension 1 pour mieux comprendre üòÄ

Nous avons une fonction  $f(x) = 3x^2 -2x +5$ et nous souhaitons minimiser cette fonction

`<u>`Graphique N¬∞4 :Exemple descente de gradient `</u>`

<img src="https://github.com/Roulitoo/cours_iae/blob/master/00_intro/img/exemple_grad_1D_4.png" alt="fonction_exemple_4.png" style="width:500px;"/>

**Etape 1 : On calcule son vecteur gradient **

En dimension le vecteur est de taille 1, donc on calcule uniquement une d√©riv√©e

$f'(x) = 6x -2$

**Etape 2 : On initialise une valeur de $x$ par d√©faut et une valeur pour le learning rate**

On pose $x_0 = 5$ et $\eta = 0.05$

La formule pour les √©tapes de descente de gradient en D1 est donc :
$x_{n+1} = x_n -\eta*f'(x_n)$

**Etape 3 : It√©ration sucessive descente de gradient**

`<u>`Graphique N¬∞5 :Exemple descente de gradient `</u>`

<img src="https://github.com/Roulitoo/cours_iae/blob/master/00_intro/img/descente_grad_exemple_5.png" alt="fonction_exemple_descente_grad_5.png" style="width:500px;"/>

Successivement la valeur de $\theta$ se rapproche de la valeur de $x=\frac{1}{3}$ qui minise la fonction.
Quand vous utiliserez l'hyperparam√®tre **learning rate** pour un algo de machine learning c'est exactement ca qui se passera en back.

> Vous savez maintenant ce qu'est la descente de gradient, bravo !

## 2.4-LOSS function or Metric function?

Les 2 termes sont souvent confondus dans le domaine du machine learning mais il repr√©sente pourtant 2 concepts bien diff√©rents.

#### Loss function

La *loss function* ou *cost function* est utilis√©e pour entrainer notre mod√®le de ML et c'est la fonction que nous allons chercher √† optimiser (minimiser ou maximiser) les param√®tres du mod√®le.

Globalement elle donne l'√©cart entre la qualit√© de notre pr√©diction et la valeur de r√©f√©rence.

Exemple :

- Logistic sigmoid
- Mean squared error
- Cross-Entropy
- Hinge loss
- etc

#### Metric function

La *Metric function* est quant √† lui un crit√®re a post√©riori qui permet d'√©valuer la qualit√©/performance du mod√®le. C'est un quantifieur permettant au cr√©ateur du mod√®le d'√©valuer si son mod√®le est bon ou mauvais.

Exemple :

- Accuracy
- F1 Score
- Recall
- etc

#### Spoiler

Certaines $Loss function$ sont aussi des $Metric function$, c'est quasi tout le temps le cas pour les mod√®les de r√©gression!

> Toutes les loss function de scikit : https://scikit-learn.org/stable/modules/model_evaluation.html

## 2.5-Hyperpam√®tre

Il ne faut pas confondre les param√®tres d'un mod√®le qui d√©pendent directement des donn√©es et sont calcul√©s analytiquement avec les hyperparam√®tres.

Tous les mod√®les de machine learning n'en poss√®dent pas. Par exemple la r√©gression lin√©aire ne poss√®de aucun hyperparam√®tre, l'ensemble de ses param√®tres est calcul√© √† partir des donn√©es.

En revanche, les mod√®les de machine learning complexes en poss√®dent √©normement. Ils permettent de contr√¥ler l'apprentissage du mod√®le et impactent donc directement les param√®tres du mod√®le.
Leur valeur n'est pas connue √† l'avance et la seule fa√ßon de trouver la combinaison optimale est de faire varier leur valeur tout en observant l'impact sur la fonction de perte.

Exemple :

- Le learning rate
- Regularization parameter (ridge, lasso,...)
- Max depth, Max features ( random forest, ...)

> Pour approndir
> https://towardsdatascience.com/parameters-and-hyperparameters-aa609601a9ac

## 2.6-Grid search

Le moyen le plus simple de trouver les valeurs de vos hyperparam√®tres qui maximise ou minimise ou votre *loss function* est de r√©aliser un *grid search*.

C‚Äôest une m√©thode d‚Äôoptimisation (hyperparameter optimization) qui va nous permettre de tester une s√©rie de param√®tres et de comparer les performances pour en d√©duire le meilleur param√©trage.
On d√©finit une plage de valeur possible pour nos hyperparam√®tres et toutes les combinaisons seront test√©es pour voir lesquelles donnent le meilleur mod√®le.

Il existe 3 types de grid search :

- **Grid search** : On d√©finit manuellement une grille de combinaison des hyperparam√®tres. Plus vous aurez de l'exp√©rience plus il sera facile de d√©finir les hyperparam√®tres et donc r√©duire l'espace de la grille.
- **Random Grid search** : On d√©finit une grille dans lequel les hyperparam√®tres prennent leur valeur dans un espace que nous lui fournissons. Dans l'ensemble de cet espace, il va chercher les hyperparam√®tres qui donne le meilleu r√©sultat.

On peut voir graphiquement le r√©sultat des 2 approches.

`<u>`Graphique N¬∞6 :Visualisation grid search avec 2 hyperparam√®tres `</u>`

<img src="https://github.com/Roulitoo/cours_iae/blob/master/00_intro/img/grid_search_6.png" alt="gris_search_6.png" style="width:1000px;"/>

Le random search donne g√©n√©ralement de meilleure performance mais il est aussi beaucoup plus couteux en temps de calcul... A vous d'arbitrer.

- **Bayesian Grid search** :  Cette m√©thode diff√©re des autres car elle va s√©lectionner les hyperparam√®tres √† chaque entrainement de mod√®le conditionnelement aux r√©sultats du pr√©c√©dent. Th√©oriquement la combinaison de meilleur param√®tre sera trouv√© plus vite que pour les 2 pr√©c√©dents et elle retira automatiquement les espaces o√π la combinaison d'hyperparam√®tre est mauvaise. Comme pour les 2 autres, il faut fournir au d√©part l'espace o√π tester les hyperparam√®tres.

Pour impl√©menter ces m√©thodes en python, vous pouvez utiliser les codes suivants :

```python
#Import function
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

#Define grid
param_grid = {
    "max_samples": [0.2, 0.3, 0.4, 0.4, 0.1],
    "max_features": [1, 2],
    "max_depth": [ 4, 20,] 
            }
#Grid
reg_grid = GridSearchCV(RandomForestClassifier(),
                        param_grid=param_grid,
                        cv=5,
                        n_jobs=4, 
                        scoring='accuracy'
                       )

#Fit model
model_grid = reg_grid.fit(X, y)
#get best estimator
model_grid.best_estimator_

```

#### Random search

```python
#Import function
from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from scipy.stats import uniform, randint

#Define grid
param_grid = {
    "max_samples": uniform(1e-2, 0.5),
    "max_features": randint(1,2),
    "max_depth": randint(4, 400) 
}

# Random
reg_rand = RandomizedSearchCV(RandomForestClassifier(),
                         param_distributions=param_grid,
                         cv=5,
                         n_jobs=4,
                         scoring='accuracy',
                         random_state=42)
#Fit model
model_rand = reg_rand.fit(X, y)

#Print best estimator
print(model_rand.best_estimator_)

```

#### Bayesian search

```python
#! pip install scikit-optimize
from skopt import BayesSearchCV
# parameter ranges are specified by one of below
from skopt.space import Real, Categorical, Integer
#Real : Nombre r√©el
#Categorial : data cat√©gorielle, exemple 'bleu', 'rouge'
#Integer : ...

#Define grid
param_grid = {
    "max_samples": Real(1e-2, 0.5),
    "max_features": Integer(1,2),
    "max_depth": Integer(4, 400) 
}
#grid
reg_bay = BayesSearchCV(estimator=RandomForestClassifier(),
                    search_spaces=param_grid,
                    cv=5,
                    n_jobs=8,
                    scoring='accuracy',
                    random_state=42)
#Fit the data
model_bay = reg_bay.fit(X, y)
#Meilleur estimateur
print(model_bay.best_estimator_)

```

> Article int√©ressant sur le grid search et random search
> https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/
> Comparaison 3 types de grid search, article
> https://towardsdatascience.com/bayesian-optimization-for-hyperparameter-tuning-how-and-why-655b0ee0b399
> Doc impl√©mentation bayesian grid search
> https://scikit-optimize.github.io/stable/index.html

## 2.7-Learning curve

En mod√©lisation on dit souvent que "plus on a de data plus le mod√®le sera pr√©cis". Cette affirmation est vraie, augmenter le nombre de data am√©liore g√©n√©ralement les performance des mod√®les.`<br>`
`<br>`
Cependant, il existe une quantit√© de data √† partir duquel le mod√®le arr√™te d'apprendre. Autrement dit rajouter des donn√©es ne sert √† rien √† part augmenter le temps de calcul!
Cela peut venir du fait qu'il existe un parttern simple dans vos donn√©es et le mod√®le apprend tr√®s vite ou malheuresement que vos donn√©es ne permettent de pas d'expliquer le ph√©nom√®ne √©tudi√©.

Une mani√®re de visualiser cette relation quantit√© de data et performance du mod√®le est d'utiliser des learning curve.

On it√®re plusieurs mod√©lisations du m√™me mod√®le sans faire varier les hyperparam√®tres mais on entraine syst√©matiquement avec un peu plus de data pour voir l'impact sur la qualit√© du mod√®le.

G√©n√©ralement on repr√©sente cette technique avec un graphique qui ressemble √† celui ci-dessous :

`<u>`Graphique N¬∞7 :Visualisation learning curve `</u>`

<img src="https://github.com/Roulitoo/cours_iae/blob/master/00_intro/img/learning_curve_7.png" alt="learning_curve_7.png" style="width:600px;"/>

Pour impl√©menter ce type de graphique nous utilisons encore une fois [sklearn](https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html)

```python
#Ploting learnin curve
from sklearn.model_selection import learning_curve
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

import numpy as np

#Split in train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=1)
#Model
lr = LogisticRegression(max_iter = 1000 , random_state= 42)

# Use learning curve to get training and test scores along with train sizes
#Learning curve function with train_sizes = d√©coupage du dataset en 10 de 10% √† 100%
train_sizes, train_scores, test_scores = learning_curve(estimator=lr, 
                                                        X=X_train, 
                                                        y=y_train,
                                                        cv=10, 
                                                        train_sizes=np.linspace(0.1, 1.0, 10),
                                                       )

#
# Trop de fluctuation dans le mod√®le, on calcule la moyenne des m√©triques
#
train_mean = np.mean(train_scores, axis=1)
train_std = np.std(train_scores, axis=1)
test_mean = np.mean(test_scores, axis=1)
test_std = np.std(test_scores, axis=1)
#
# Plot the learning curve
#
plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training Accuracy')
plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')
plt.plot(train_sizes, test_mean, color='green', marker='+', markersize=5, linestyle='--', label='Validation Accuracy')
plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')
plt.title('Learning Curve')
plt.xlabel('Training Data Size')
plt.ylabel('Model accuracy')
plt.grid()
plt.legend(loc='lower right')
plt.show()

```

## 2.8-Computational complexity

En machine learning, le $computational complexity$ ou complexit√© de l'algorithme est le montant de ressources n√©cessaires pour utiliser un mod√®le.
On distingue le temps d'entrainement d'un mod√®le et le temps de pr√©diction d'un mod√®le d√©ja entrain√©.

A titre d'exemple.

La r√©gression lin√©aire impl√©ment√©e avec sklearn poss√®de une complexit√© de $O(n_{samples} n^2_{features})$.
Si on double le nombre de lignes et de colonnes du dataset, on augmente alors de $2.2^2 = 8$  le temps de calcul. Un temps de calcul alors 8 fois plus long.

En revanche la pr√©diction ne d√©pend que du nombre de colonnes $O(n_{features})$

> Tableau comparaison model complexity :https://www.thekerneltrip.com/machine/learning/computational-complexity-learning-algorithms/

## 2.9-Les data pipelines

Une data pipeline ou "chaine de traitement data" est un processus visant √† ing√©rer l'ensemble des donn√©es brutes afin de les d√©placer dans un syst√®me permettant de les traiter et les transformer afin de les adapter √† un enjeu ou des enjeux finaux.

Ce terme provient du domaine de l'engineering o√π les Data Ing√©nieur sont souvent amen√©s √† traiter d'√©normes volumes de donn√©es afin de les rendre exploitable par des Data Scientist, Data Analyst, Business Analyst, Charg√© d'√©tudes, ...

Ce traitement suit plusieurs phases :

- L'identifiant des data sources : database SQL ou NOSQL, API, Fichiers, Server, ...)
- Business logic : Transformation des donn√©es brutes pour ressembler le plus possible au contexte o√π elles sont cr√©√©es
- Data destination /target :  Lieu o√π nous allons les stocker (Data warehouse, Data Lake)
- Orchestration :  Quand  allons-nous ex√©cuter toutes ces phases? Que faire s'il ya une erreur, ...

> Donner un exemple avec un ETL

### La transposition des data pipeline au machine learning

Cr√©er un algorithme de machine learning demande la r√©alisation de nombreuses t√¢ches. Ces t√¢ches se d√©composent souvent s√©quentiellement et vont de l'extraction de donn√©es pour constituer son dataset, le nettoyage de ses donn√©es, l'ajout de donn√©es avec votre expertise, l'entrainement du mod√®le, son d√©ploiement et le suivi de ses performances.

Ces √©tapes individuelles jouent un r√¥le essentiel dans la mise en production industrielle des mod√®les de machine learning. Aujourd'hui, il est impensable d'ex√©cuter manuellement ces t√¢ches les unes apr√®s les autres.

Ces pourquoi les Data Scientist ont d√©cid√© d'appliquer les meilleures pratiques des Data Pipelines √† nos probl√©matiques de cr√©ation de mod√®les.

![chaine ml](cours_iae\00_intro\img\machine_learning_pipeline.png)

Cette chaine de traitement s'associe √† de bonne pratique :

![mlops_chaine](cours_iae\00_intro\img\mlops.png)

## 2.9-Python environnement virtuel

Python ne sait pas versionner les packages. Quand vous r√©aliser un *pip install*, la version que vous t√©l√©chargez √©crase la pr√©c√©dente.

Cela peut poser de grave probl√®me si vous mettez √† jour vos packages, potentiellement vos anciens codes seront en erreur
car la nouvelle version du package √† supprimer une fonction ou l'a tout simplement modifi√©e...

Prenons un exemple, je d√©veloppe pour le projet ann & svm en python 3.7 et pandas 1.2 la fonction suivante :

```python
import pandas as pd

def calcul_moyenne_par_groupe(dataframe, colonne_groupe, colonne_valeur):
    resultats = dataframe.groupby(colonne_groupe).agg({colonne_valeur: 'mean'}).reset_index()
    return resultats

```

Maintenant pour un projet sp√©cifique j'ai besoin de pandas 1.0 que je t√©l√©charger avec *pip install*.`<br>`
Je relance mon code python avec la nouvelle version de pandas et voil√† ce que j'obtiens:

```python
Cette version de Pandas ne prend pas en charge la m√©thode 'agg' de cette mani√®re. Mettez √† jour vers une version plus r√©cente de Pandas pour utiliser cette fonction.

```

**Heuresement** il existe une solution pour ce pr√©munir de ce genre de probl√®me.`<br>`
Les environnements virtuels!!

![Alt text](https://raw.githubusercontent.com/Roulitoo/cours_iae/master/00_intro/img/pyenv.png)

Comment r√©aliser cette image en code

```powershell
#Comment cr√©er un venv

##Windows powershell

python -m venv mon_env #On peut sp√©cifier la version de python python3.7 -mv venv mon_env

.\mon_env\Scripts\Activate.ps1

#D√©sactiver 
deactivate

##Linux

python3 -m venv mon_env
source mon_env/bin/activate

#D√©sactiver
deactivate

```

Vous obtenez un environnement virtuel avec une version de python vide de tout package.

### Alternative avec Anaconda

Il existe une alternative plus "clique bouton" disponible avec Anaconda.
Vous pouvez suivre le tutoriel [ici](https://docs.anaconda.com/free/navigator/tutorials/manage-environments/)

### Installation de package avec version sp√©cifique

Nous allons utiliser un fichier texte communement appel√© requirements.txt qui contient le nom du package et sa version

![Alt text](https://raw.githubusercontent.com/Roulitoo/cours_iae/master/00_intro/img/requirements.png)

Apr√®s pour installer ces versions il suffit de r√©aliser la commande suivante :

```powershell
#Il faut avoir activ√© son environnement virtuel

pip install -r requirements.txt

```

> Nous venons d'illuster la c√©l√®bre phrase des data scientist. "Je ne comprends pas, ca marche sur mon pc"

## 2.10-Vscode

Visual Studio Code, souvent abr√©g√© en **VSCode**, est un √©diteur de code source gratuit et open-source d√©velopp√© par Microsoft. Il s'agit d'un outil de d√©veloppement tr√®s populaire aupr√®s des programmeurs du monde entier en raison de sa simplicit√©, de sa flexibilit√© et de sa vari√©t√© d'extensions.

Avec VSCode, vous pouvez d√©velopper des applications dans divers langages de programmation. Il offre des fonctionnalit√©s essentielles telles que la coloration syntaxique, la compl√©tion automatique, le d√©bogage int√©gr√©, la gestion de versions, et bien plus encore.

Ce logiciel a √©t√© con√ßu pour √™tre l√©ger, rapide et hautement personnalisable, ce qui en fait un choix id√©al pour les d√©veloppeurs de tous niveaux. Que vous travailliez sur des projets Web, des applications mobiles, des scripts ou des projets de donn√©es, Visual Studio Code est un outil polyvalent qui vous permet de coder de mani√®re efficace et styl√©e.

C'est un excellent choix pour les √©tudiants qui d√©couvrent le monde de la programmation, car il facilite l'apprentissage tout en offrant des fonctionnalit√©s puissantes pour le d√©veloppement de logiciels.

### Extensions √† t√©l√©chager

A gauche cliquer sur le menu extensions(4 petits carr√©s) et t√©l√©charger les extensions suivantes :

- **Python**
- **Pylance**
- **Jupyter**
- **Markdown Extended**

## 2.11-Github

GitHub est une plateforme de d√©veloppement collaboratif qui vous permet de g√©rer,
suivre et partager des projets de programmation, y compris ceux li√©s √† l'√©conom√©trie.

Que vous soyez novice en programmation ou un d√©veloppeur chevronn√©, GitHub peut √™tre un outil pr√©cieux pour faciliter le travail d'√©quipe, le suivi des versions et la collaboration sur des projets.

### Qu'est-ce que GitHub ?

GitHub est un syst√®me de contr√¥le de version (VCS) qui permet de stocker et de suivre l'√©volution des fichiers source de vos projets.

Il vous offre la possibilit√© de :

- Garder une trace des modifications apport√©es √† vos fichiers au fil du temps.
- Travailler en collaboration avec d'autres personnes sur des projets.
- G√©rer des branches pour travailler sur diff√©rentes fonctionnalit√©s ou correctifs en parall√®le.
- Faciliter la r√©solution des conflits lors de la fusion de modifications.
- Faciliter le partage de projets avec le reste du monde.

### Comment commencer avec GitHub ?

Pour commencer avec GitHub, suivez ces √©tapes simples :

1. Cr√©ez un compte GitHub : Rendez-vous sur GitHub.com et cr√©ez un compte gratuit.
2. Installez Git : Git est un logiciel de contr√¥le de version que vous devrez installer sur votre ordinateur.
   Vous pouvez le t√©l√©charger √† [partir du site officiel de Git](https://git-scm.com/download/win).
