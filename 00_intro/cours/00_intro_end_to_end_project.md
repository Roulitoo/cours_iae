    

<center><h1> Chapitre d'introduction : Projet Data et concepts utiles</h1></center>
<p align="center">
<img src="https://github.com/Roulitoo/cours_iae/blob/master/00_intro/img/Logo_IAE_horizontal.png" alt="Logo IAE.png" style="width:200px;"/>
</p>


#### Table of Contents
[1. Mener un projet data](#1-etapes-dun-projet-data)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[1.1 Bien d√©finir le probl√®me](#11-bien-d%C3%A9finir-le-probl%C3%A8me)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[1.2 Trouver les donn√©es](#12-trouver-les-donn%C3%A9es)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[1.3 Explorer les donn√©es](#13-explorer-les-donn%C3%A9es)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[1.4 Pr√©parer le dataset](#14-pr%C3%A9parer-le-dataset)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[1.5 Explorer vos mod√®les](#15-explorer-des-mod%C3%A8les-et-d%C3%A9terminer-une-short-list)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[1.6 Tuner les mod√®les](#16-tuner-les-mod%C3%A8les)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[1.7 Pr√©senter votre solution](#17-pr%C3%A9senter-votre-solution)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[1.8 Automatiser,monitorer,maintenir](#18-automatiser-votre-mod%C3%A8le-monitorer-votre-mod%C3%A8le-et-le-maintenir)<br>

[2. Liste de concept utile](#-2-liste-de-concept-utile-)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[2.1 Imbalanced dataset](#21-imbalanced-dataset)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[2.2 Feature scaling](#22-features-scaling)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[2.3 Gradient descent](#23-gradient-descent)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[2.4 Loss or metric function](#24-loss-function-or-metric-function)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[2.5 Hyperparam√®tres](#25-hyperpam%C3%A8tre)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[2.6 Grid search](#26-grid-search)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[2.7 Computational complexity](#27-computational-complexity)<br>



## 1-Etapes d'un projet Data

## 1.1-Bien d√©finir le probl√®me

Bien que vous ayez un profil technique, la gestion de projets fera partie de votre m√©tier.

Chaque projet doit d'avoir un probl√®me bien cadr√© sinon vous allez dans le mur!  
Si vous n'√™tes pas en mesure de d√©finir le probl√®me, vous ne saurez pas √† quoi r√©pondre et donc vous ne pourrez rien d√©velopper ou alors vous r√©pondrez √† c√¥t√© dans **90%** des cas!

Pour ce faire vous pouvez suivre les recommandations suivantes :

##### Explorez la probl√©matique qui vous est pos√©e.
Quel est le probl√®me?  
Pourquoi le probl√®me existe, qu'est-ce que cela engendre?  
Quelles sont les solutions pour y r√©pondre aujourd'hui?  
Mesure-t-on le probl√®me aujourd'hui?    
*S'il n'y a aucune donn√©es pour le mesurer, il sera compliqu√© pour vous de prouver a post√©riori que votre projet am√©liore quoi que ce soit.*  
Qui est impact√© par ce probl√®me?

##### Echangez, parler, identifier les personnes qui pourront r√©pondre √† vos questions
Quand on d√©bute on peut avoir envie d'aller directement √† la solution mais d√©finir le probl√®me est g√©n√©ralement le fondement du projet.   
Sauf si vous √™tes d√©ja expert dans le domaine d'application du projet, pensez √† interroger les personnes qui gravitent autour du probl√®me et ne vous lancez pas directement dans les donn√©es!

Ce seront vos interpr√©teurs cl√©s et ils vous suivront le long du projet. **Plus t√¥t vous int√©grerez les utilisateurs finaux de votre projet plus vite vous verrez si vous √™tes √©loign√© ou non de leurs attentes**



>A l'image d'un architecte, plus les plans de votre projet seront pr√©cis plus il sera facile de le d√©velopper apr√®s.
 Un probl√®me clairement sp√©cifi√© vous permettra de mieux d√©couper votre travail et vous gagnerez du temps par la suite

#####  Synth√©tiser votre travail souvent

A la fin de l'√©tape de d√©finition du probl√®me vous devriez √™tre capable de :

- D√©finir le **PROBLEME** que vous r√©glerez et le **BESOIN** auquel il r√©pond
- Mesurer avec des chiffres le probl√®me
- Expliquer votre solution et ses impactes
- D√©couper votre solution en plusieurs √©tapes

<u>Synth√©tiser ces points dans un document et pr√©senter-le</u>


##### Commencez petit

Parfois, il vaut mieux prototyper rapidement et pr√©senter votre solution avant de vous lancer dans de grands d√©veloppements.
Un prototype rapide √† d√©velopper  qu'on peut tester rapidement restera mieux qu'un projet de 2ans o√π on d√©veloppe dans son coin sans avoir de retour(parfois le pire est de travailler longtemps de son cot√© et se rendre compte que notre travail ne convient pas)






## 1.2-Trouver les donn√©es

Maintenant que vous avez un 'plan', vous savez comment r√©pondre th√©oriquement au probl√®me mais il va falloir se confronter √† la r√©alit√©.

Vous allez devoir trouver les donn√©es dont vous avez besoin pour r√©pondre √† votre probl√©matique:

**1** Lister intuitivement les donn√©es dont vous avez besoin  
<br>
**2** Trouver un interlocuteur ou un document vous expliquant o√π sont les donn√©es/ comment elles sont g√©n√©r√©es  
<br>
**3** Cr√©er vous un nouvel espace de travail( **un espace par projet**)  
<br>
**4** V√©rifier les **obligations l√©gales relatives √† vos donn√©es** (RGDP, Techniques, fuites de donn√©es, ...)  
<br>
**5** Demander des autorisations (si besoin)  
<br>
**6** Commencer √† regarder le type des donn√©es dont vous avez besoin (Image, texte, tabulaire, temporelle, g√©ographique,...)   
<br>
**7** Cr√©er un **code automatisable** pour r√©cup√©rer vos donn√©es  
<br>
**8** Structurer votre jeu de donn√©es pour que ce soit simple par la suite :
- Format des donn√©es
- Nom des colonnes
- Restriction sur votre p√©rim√®tre
   

## 1.3-Explorer les donn√©es

Dans cette partie vous allez essayer de faire ressortir les *insights* de vos donn√©es  
üí° **Pensez automatisation, si vous rajoutez des nouvelles donn√©es vous ne devez pas recoder l'analyse**

**1** Cr√©er une copie de votre dataset pour travailler dessus (diminuer le taille s'il est trop volumineux)
<br>
<br>
**2** Pour de l'exploration jupyter notebook est tr√®s bien! (on l'oubliera pour le passage en production)  
<br>
**3** Analyser vos donn√©es de fa√ßon descriptive.
> Un conseil, regarder du cot√© de [html report pandas](https://github.com/ydataai/pandas-profiling)

**4** Modifier le type de vos donn√©es si n√©cessaire  
<br>
**5** Pour une analyse supervis√©e, identifier la variable cible (target)  
<br>
**6** Visualiser les donn√©es  
<br>
**7** Etudier les corr√©lations  
<br>
**8** R√©fl√©chir √† comment r√©soudre le probl√®me en tant qu'humain sans coder      
&nbsp;&nbsp;&nbsp;Quelles informations utiliseriez-vous? Comment le feriez-vous?  
&nbsp;&nbsp;&nbsp;Apr√®s l'avoir fait, essayer de transposer ca en code  
**9** Commencer le *feature engineering* pour cr√©er des nouvelles features  
<br>
**10** Retourner √† l'√©tape 2 s'il manque des donn√©es  

> Pensez √† Documenter vos trouvailles, documenter, documenter, documenter!

## 1.4-Pr√©parer le dataset

üí°Travailler sur une copie du dataset  
üí°Ecrivez des functions et pas du code non r√©utilisable 

### Plan pour pr√©parer son dataset    

- 1) **Data cleaning** (outliers, NA value, ...)  


- 2) **Feature selection**(si besoin)  

    - Etudes des corr√©lations
    - Variables d'importances
    - R√©gression p√©nalis√©e
    - Stats descriptives


- 3) **Feature engineering** adatp√© √† vos besoins  

    - Discr√©tiser vos donn√©es continues
    - Recoder variables cat√©gorielles
    - Ajouter des transformations de features
    - Agr√©ger des features  


- 4) **Feature scaling** 

    - Standardiser ou normaliser vos features
    
    
> Ce [bouquin](https://www.oreilly.com/library/view/feature-engineering-for/9781491953235/) est pas mal si ca vous int√©resse d'en savoir plus<br>
> Un site pour la [Feature selection](https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/])


## 1.5-Explorer des mod√®les et d√©terminer une short-list 

1) Entrainer des mod√®les avec les hyperparam√®tres par d√©faut  
     *Des mod√®les avec des paradigmes diff√©rents (regressions, arbres, svm, neural net, xgboost,...*
     
     
**2** Mesurer les performances de chaque mod√®le  
&nbsp;&nbsp;&nbsp;*Utiliser une cross-validation avec n-fold*
     
     
**3** Analyser les variables d'importances pour chaque mod√®le


**4** Analyser les erreurs du mod√®le


**5** R√©aliser une liste des features pertinents


**6** Essayer de changer d'am√©liorer rapidement vos pr√©c√©dents mod√®les


**7** Garder une liste des 3 meilleurs mod√®les

## 1.6-Tuner les mod√®les

üèÅ Vous allez maintenant utiliser l'ENSEMBLE de vos donn√©es pour obtenir le meilleur mod√®le possible

**1** Tunez vos mod√®les en utilisant une cross validation
- Par exp√©rience, je vous conseille de traiter votre feature engineering comme un hyperparam√®tre.
  Surtout si vous n'√™tes pas s√ªr de votre strat√©gie (ie, imputation NA, r√©unification Data, ...)
      
- Random grid, search, bayesian grid search
    
**2** Si vos mod√®les offres des performances faibles, testez les [mod√®les ensemblistes](https://scikit-learn.org/stable/modules/ensemble.html)

**3** Quand votre mod√®le est suffisament performant sur le **training test**, mesurer sa performance avec le **test set**

## 1.7-Pr√©senter votre solution

**1** Documentez votre projet  
&nbsp;&nbsp;&nbsp;*Pensez bien √† expliquer les choix que vous avez faits*

**2** Cr√©er une pr√©sentation sympa (pas de word SVP)  
&nbsp;&nbsp;&nbsp;*Mettez en avant les informations importantes*
     
**3** Expliquer concr√®tement comment votre projet r√©pond au besoin business (besoin de d√©part)

**4** Pensez √† comment vous allez vendre votre projet!  
&nbsp;&nbsp;&nbsp;*Si vous n'√™tes pas dans une entreprise tech, il sera parfois compliqu√© de prouver que votre mod√®le est utile.*<br>
&nbsp;&nbsp;&nbsp;*Faites de la com, soyez imaginatif*
     

## 1.8-Automatiser votre mod√®le, monitorer votre mod√®le et le maintenir

**1** Pr√©parer votre code pour passer en production 

**2** Pr√©parer un monitoring de votre code

- Suivre la performance de votre mod√®le (KPI)
- Suivre que votre mod√®le s'excute bien
- V√©rifier que le mod√®le ne se d√©grade pas
- Mesurer qu'il n'y a pas de d√©rive sur vos donn√©es
    
**3** Faites r√©guli√®rement des points avec le business pour prouver que votre solution am√©liore la situation

<center><h1> 2-Liste de concept utile </h1></center>

## 2.1-Imbalanced dataset

Le cas le plus commun de donn√©es d√©s√©quilibr√©es est une classification binaire.

Prenons l'exemple d'une fraude √† la carte bancaire.  
Nous avons un data set contenant 1 million d'op√©rations bancaires. La fraude √©tant un √©l√©ment rare (heuresement) notre data set ne contient que 10 000 fraudes pour 990 000 non fraudes.

Si nous entrainons un mod√®le de machine learning pour une classification binaire sur ce projet, il sera incapable d'apprendre ce qu'est une fraude car nous ne lui pr√©senterons pas suffisamment d'exemple pour qu'il arrive √† d√©finir une fraude.

Imaginons tout de m√™me que nous entrainions tout de m√™me un mod√®le logit sur ce dataset.  
**Le mod√®le donne une accuracy de 89%** 
> Est-ce une bonne nouvelle, le mod√®le est-il pertinent?

On aurait tendance √† dire oui car 89% de bonne pr√©diction semble √™tre une valeur √©lev√©e mais 89% est plus faible qu'une pr√©diction na√Øve...

Un algo qui dirait syst√©matiquement qu'une op√©ration n'est pas une fraude aurait raison √† 99% du temps 99000/1000000.


Si vous √™tes confront√© √† ce genre de probl√®me, vous pouvez utiliser les m√©thodes suivantes :

- **Upsampling** : Augmenter l'√©v√©nement rare avec un tirage al√©atoire avec replacement
- **Downsampling** : Diminuer l'√©v√©nement non rare en retirant des cas
- **Oversampling** : Algorithme ROSE ou SMOTE cr√©ant artificiellement de nouveaux cas rares

> Lien pour smote et rose https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/



## 2.2-Features scaling

Le scaling feature (mettre vos donn√©es √† la m√™me √©chelle) permet d'exprimer diff√©rentes features avec diff√©rentes grandeurs num√©riques dans une m√™me unit√©s.


Il exite 2 grandes familles pour le feature scaling :

- La normalisation

- La standardisation

Les 2 permettent d'exprimer les colonnes num√©riques dans une m√™me unit√©s, am√©liorer le temps de calcul des mod√®les et pour certain mod√®le donner de meilleures performances.

### Normalisation

La normalisation est le fait de transformation vos features dans une √©chelle [0,1]. On l'appelle parfois *min-max scaling*.
Sa formule est la suivante

$X_{norm} = \frac{X-X_{min}}{X_{max}-X_{min}}$

```python
from sklearn.preprocessing import MinMaxScaler
#Exmple
data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]
scaler = MinMaxScaler() 
print(scaler.fit_transform(data))
```

### Standardisation

La standardisation est une technique qui permet quant √† elle de transformer nos colonnes en variable avec une moyenne de 0 et un √©cart type de 1.  
Les colonnes transform√©es auront donc les m√™mes param√®tres de distribution.
La standardisation pr√©sente des avantages quand il existe des outliers, comme on utilise pas la valeur Min et Max, la technique y est moins sensible!  

$z = \frac{X-\mu}{\sigma}$

```python 
from sklearn.preprocessing import StandardScaler
data = [[4, 8], [-5, 25], [4, 1], [9, 2.5]]
scaler = StandardScaler()
print(scaler.fit_transform(data))

```

> Article int√©ressant : https://towardsdatascience.com/normalization-vs-standardization-quantitative-analysis-a91e8a79cebf

## 2.3-Gradient Descent

Quand vous calculez les param√®tres de votre mod√®le vous avez 2 possibilit√©s :


- Utiliser une r√©solution math√©matique pour obtenir la solution optimale (exemple, r√©solution MCO reg lin√©aire)  


- Utiliser une r√©solution d'optimisation successive appell√©e **Descent de Gradient** qui va chercher it√©rativement les param√®tres qui minisent la fonction de co√ªt du mod√®le


> Plus d'informations ici https://developers.google.com/machine-learning/crash-course/reducing-loss/an-iterative-approach


Concr√®tement vous commencez avec un param√®tr $\theta$ donn√© et vous allez le faire varier it√©rativement en fonction de la valeur de sa d√©riv√©e.  
On peut l'observer graphiquement sur le graphique N¬∞1



<u>Graphique N¬∞1 :Descente de gradient</u>

<img src="https://github.com/Roulitoo/cours_iae/blob/master/00_intro/img/descente_gradient_1.png" alt="fig_1_descente_gradient.png" style="width:600px;"/>

Chaque point rouge repr√©sente une it√©ration de descente de gradient et converge vers le minimum global de la fonction de perte.  
Nous obtenons en ce point pour un param√®tre $\theta$ dont la valeur minimise notre fonction de perte. 


<u>Graphique N¬∞2 :Descente de gradient, learning rate trop faible</u>

<img src="https://github.com/Roulitoo/cours_iae/blob/master/00_intro/img/descente_gradient_2.png" alt="fig_2_descente_gradient.png" style="width:600px;"/>

Il est important que la taille du 'saut' de mise √† jour de la valeur de votre param√®tre $\theta$ ne soit pas trop faible.
On appellera le param√®tre qui contr√¥le le 'saut' **LEARNING RATE**.  
Si celui-ci est trop faible vos 'sauts' seront petits, il faudra beaucoup d'it√©rations avant de trouver le param√®tre optimal.


<u>Graphique N¬∞3 :Descente de gradient, learning rate trop haut</u>

<img src="https://github.com/Roulitoo/cours_iae/blob/master/00_intro/img/descente_gradient_3.png" alt="fig_3_descente_gradient.png" style="width:600px;"/>

A l'inverse si le *LEARNING RATE* est trop √©lev√© vous pourriez ne jamais trouver l'optimal de votre fonction.  
Le calcul divergera et ne trouvera jamais de minimum local.

Un peu de math pour comprendre la descente de gradientüòÄ.
C'est un concept fondamental pour les algorithmes de machine learning!!

Exemple de descente de gradient avec **fonction de co√ªt MSE** pour un mod√®le lin√©aire:

On d√©finit une fonction lin√©aire avec un vecteur de param√®tre $\theta$  
$\widehat{y} = \theta_0 + \theta_1x1+...+\theta_nxn$

o√π  :

- $\theta_0 : Biais\space du\space modele $
- $\theta_n : Param√®tre \space du \space mod√®le$
- $\widehat{y} : Valeur\space pr√©dite$
- $n : Nombre \space de \space features$


Au format vectoriel nous avons l'√©quation suivante :

$\widehat{y} = h_\theta(x) = \theta.X$

On d√©finit la fonction de perte de ce mod√®le comme :

$MSE(X, h_\theta) = \frac{1}{N}\sum_{i=1}^N (y_i-\widehat{y_i})¬≤$

Pour impl√©menter la descente de gradient, vous devez calculer le gradient de la fonction de co√ªt MSE en fonction de ses param√®tres $\theta$
On doit donc calculer toutes les d√©riv√©es partielles de la fonction MSE

$\frac{\partial}{\partial \theta_j} MSE(\theta) = \frac{2}{N}\sum_{i=1}^N (\theta^Tx^{(i)}-y^{(i)})x^{(i)}_j$
  
ou au format vectoriel

$$\nabla_\theta MSE(\theta) = \begin{pmatrix}  \frac{\partial}{\partial \theta_0} \\ \frac{\partial}{\partial \theta_1} \\ . \\frac{\partial}{\partial \theta_n}  \end{pmatrix} =\frac{2}{N}X^T (X\theta-y)$$ 

Une fois que vous avez le vecteur de descente de gradient, vous devez simplement mettre √† jour vos param√®tres $\theta$ jusqu'√† atteindre le minimum de votre fonction.

$\theta^{(next)} = \theta - \eta\nabla_\theta MSE(\theta)$

#### Exemple descente de gradient
Un exemple en dimension 1 pour mieux comprendre üòÄ

Nous avons une fonction  $f(x) = 3x^2 -2x +5$ et nous souhaitons minimiser cette fonction

<u>Graphique N¬∞4 :Exemple descente de gradient</u>

<img src="https://github.com/Roulitoo/cours_iae/blob/master/00_intro/img/exemple_grad_1D_4.png" alt="fonction_exemple_4.png" style="width:500px;"/>

**Etape 1 : On calcule son vecteur gradient **

En dimension le vecteur est de taille 1, donc on calcule uniquement une d√©riv√©e

$f'(x) = 6x -2x$
 
**Etape 2 : On initialise une valeur de $x$ par d√©faut et une valeur pour le learning rate**

On pose $x_0 = 5$ et $\eta = 0.05$

La formule pour les √©tapes de descente de gradient en D1 est donc :
$x_{n+1} = x_n -\eta*f'(x_n)$

**Etape 3 : It√©ration sucessive descente de gradient**

<u>Graphique N¬∞5 :Exemple descente de gradient</u>

<img src="https://github.com/Roulitoo/cours_iae/blob/master/00_intro/img/descente_grad_exemple_5.png" alt="fonction_exemple_descente_grad_6.png" style="width:500px;"/>


Successivement la valeur de $\theta$ se rapproche de la valeur de $x=\frac{1}{3}$ qui minise la fonction.
Quand vous utiliserez l'hyperparam√®tre **learning rate** pour un algo de machine learning c'est exactement ca qui se passera en back.

> Vous savez maintenant ce qu'est la descente de gradient, bravo !

## 2.4-LOSS function or Metric function?

Les 2 termes sont souvent confondus dans le domaine du machine learning mais il repr√©sente pourtant 2 concepts bien diff√©rents.

#### Loss function
La *loss function* ou *cost function* est utilis√©e pour entrainer notre mod√®le de ML et c'est la fonction que nous allons chercher √† optimiser (minimiser ou maximiser) les param√®tres du mod√®le.  

Globalement elle donne l'√©cart entre la qualit√© de notre pr√©diction et la valeur de r√©f√©rence.

Exemple : 

- Logistic sigmoid
- Mean squared error
- Cross-Entropy
- Hinge loss
- etc



#### Metric function

La *Metric function* est quant √† lui un crit√®re a post√©riori qui permet d'√©valuer la qualit√©/performance du mod√®le. C'est un quantifieur permettant au cr√©ateur du mod√®le d'√©valuer si son mod√®le est bon ou mauvais.

Exemple : 

- Accuracy
- F1 Score
- Recall
- etc


#### Spoiler

Certaines $Loss function$ sont aussi des $Metric function$, c'est quasi tout le temps le cas pour les mod√®les de r√©gression!

>Toutes les loss function de scikit : https://scikit-learn.org/stable/modules/model_evaluation.html

## 2.5-Hyperpam√®tre

Il ne faut pas confondre les param√®tres d'un mod√®le qui d√©pendent directement des donn√©es et sont calcul√©s analytiquement avec les hyperparam√®tres.

Tous les mod√®les de machine learning n'en poss√®dent pas. Par exemple la r√©gression lin√©aire ne poss√®de aucun hyperparam√®tre, l'ensemble de ses param√®tres est calcul√© √† partir des donn√©es.

En revanche, les mod√®les de machine learning complexes en poss√®dent √©normement. Ils permettent de contr√¥ler l'apprentissage du mod√®le et impactent donc directement les param√®tres du mod√®le.
Leur valeur n'est pas connue √† l'avance et la seule fa√ßon de trouver la combinaison optimale est de faire varier leur valeur tout en observant l'impact sur la fonction de perte.


Exemple :

- Le learning rate 
- Regularization parameter (ridge, lasso,...)
- Max depth, Max features ( random forest, ...)

>Pour approndir
>https://towardsdatascience.com/parameters-and-hyperparameters-aa609601a9ac


## 2.6-Grid search

Le moyen le plus simple de trouver les valeurs de vos hyperparam√®tres qui maximise ou minimise ou votre *loss function* est de r√©aliser un *grid search*.

C‚Äôest une m√©thode d‚Äôoptimisation (hyperparameter optimization) qui va nous permettre de tester une s√©rie de param√®tres et de comparer les performances pour en d√©duire le meilleur param√©trage.
On d√©finit une plage de valeur possible pour nos hyperparam√®tres et toutes les combinaisons seront test√©es pour voir lesquelles donnent le meilleur mod√®le.



Il existe 3 types de grid search :

- **Grid search** : On d√©finit manuellement une grille de combinaison des hyperparam√®tres. Plus vous aurez de l'exp√©rience plus il sera facile de d√©finir les hyperparam√®tres et donc r√©duire l'espace de la grille.


- **Random Grid search** : On d√©finit une grille dans lequel les hyperparam√®tres prennent leur valeur dans un espace que nous lui fournissons. Dans l'ensemble de cet espace, il va chercher les hyperparam√®tres qui donne le meilleu r√©sultat.

On peut voir graphiquement le r√©sultat des 2 approches.

<u>Graphique N¬∞5 :Visualisation grid search avec 2 hyperparam√®tres</u>

<img src="https://github.com/Roulitoo/cours_iae/blob/master/00_intro/img/grid_search_6.png" alt="gris_search.png" style="width:1000px;"/>

Le random search donne g√©n√©ralement de meilleure performance mais il est aussi beaucoup plus couteux en temps de calcul... A vous d'arbitrer.

- **Bayesian Grid search** :  Cette m√©thode diff√©re des autres car elle va s√©lectionner les hyperparam√®tres √† chaque entrainement de mod√®le conditionnelement aux r√©sultats du pr√©c√©dent. Th√©oriquement la combinaison de meilleur param√®tre sera trouv√© plus vite que pour les 2 pr√©c√©dents et elle retira automatiquement les espaces o√π la combinaison d'hyperparam√®tre est mauvaise. Comme pour les 2 autres, il faut fournir au d√©part l'espace o√π tester les hyperparam√®tres.



Pour impl√©menter ces m√©thodes en python, vous pouvez utiliser les codes suivants :

```python
#Import function
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

#Define grid
param_grid = {
    "max_samples": [0.2, 0.3, 0.4, 0.4, 0.1],
    "max_features": [1, 2],
    "max_depth": [ 4, 20,] 
            }
#Grid
reg_grid = GridSearchCV(RandomForestClassifier(),
                        param_grid=param_grid,
                        cv=5,
                        n_jobs=4, 
                        scoring='accuracy'
                       )

#Fit model
model_grid = reg_grid.fit(X, y)
#get best estimator
model_grid.best_estimator_

```


#### Random search

```python 
#Import function
from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from scipy.stats import uniform, randint

#Define grid
param_grid = {
    "max_samples": uniform(1e-2, 0.5),
    "max_features": randint(1,2),
    "max_depth": randint(4, 400) 
}

# Random
reg_rand = RandomizedSearchCV(RandomForestClassifier(),
                         param_distributions=param_grid,
                         cv=5,
                         n_jobs=4,
                         scoring='accuracy',
                         random_state=42)
#Fit model
model_rand = reg_rand.fit(X, y)

#Print best estimator
print(model_rand.best_estimator_)

```
#### Bayesian search

```python 
#! pip install scikit-optimize
from skopt import BayesSearchCV
# parameter ranges are specified by one of below
from skopt.space import Real, Categorical, Integer
#Real : Nombre r√©el
#Categorial : data cat√©gorielle, exemple 'bleu', 'rouge'
#Integer : ...

#Define grid
param_grid = {
    "max_samples": Real(1e-2, 0.5),
    "max_features": Integer(1,2),
    "max_depth": Integer(4, 400) 
}
#grid
reg_bay = BayesSearchCV(estimator=RandomForestClassifier(),
                    search_spaces=param_grid,
                    cv=5,
                    n_jobs=8,
                    scoring='accuracy',
                    random_state=42)
#Fit the data
model_bay = reg_bay.fit(X, y)
#Meilleur estimateur
print(model_bay.best_estimator_)

```



> Article int√©ressant sur le grid search et random search  
>https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/  
> Comparaison 3 types de grid search, article  
>https://towardsdatascience.com/bayesian-optimization-for-hyperparameter-tuning-how-and-why-655b0ee0b399  
> Doc impl√©mentation bayesian grid search  
>https://scikit-optimize.github.io/stable/index.html

## 2.7-Computational complexity 

En machine learning, le $computational complexity$ ou complexit√© de l'algorithme est le montant de ressources n√©cessaires pour utiliser un mod√®le.
On distingue le temps d'entrainement d'un mod√®le et le temps de pr√©diction d'un mod√®le d√©ja entrain√©.

A titre d'exemple.

La r√©gression lin√©aire impl√©ment√©e avec sklearn poss√®de une complexit√© de $O(n_{samples} n^2_{features})$.
Si on double le nombre de lignes et de colonnes du dataset, on augmente alors de $2.2^2 = 8$  le temps de calcul. Un temps de calcul alors 8 fois plus long.

En revanche la pr√©diction ne d√©pend que du nombre de colonnes $O(n_{features})$

> Tableau comparaison model complexity :https://www.thekerneltrip.com/machine/learning/computational-complexity-learning-algorithms/
