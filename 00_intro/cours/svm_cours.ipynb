{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "\n",
    "<center><h1> Chapitre d'introduction : Projet Data et concepts utiles</h1></center>\n",
    "<p align=\"center\">\n",
    "<img src=\"https://github.com/Roulitoo/cours_iae/blob/master/00_intro/img/Logo_IAE_horizontal.png\" alt=\"Logo IAE.png\" style=\"width:200px;\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "#### Table of Contents\n",
    "[1. Mener un projet data](#1-etapes-dun-projet-data)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[1.1 Bien d√©finir le probl√®me](#11-bien-d%C3%A9finir-le-probl%C3%A8me)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[1.2 Trouver les donn√©es](#12-trouver-les-donn%C3%A9es)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[1.3 Explorer les donn√©es](#13-explorer-les-donn%C3%A9es)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[1.4 Pr√©parer le dataset](#14-pr%C3%A9parer-le-dataset)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[1.5 Explorer vos mod√®les](#15-explorer-des-mod%C3%A8les-et-d%C3%A9terminer-une-short-list)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[1.6 Tuner les mod√®les](#16-tuner-les-mod%C3%A8les)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[1.7 Pr√©senter votre solution](#17-pr%C3%A9senter-votre-solution)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[1.8 Automatiser,monitorer,maintenir](#18-automatiser-votre-mod%C3%A8le-monitorer-votre-mod%C3%A8le-et-le-maintenir)<br>\n",
    "\n",
    "[2. Liste de concept utile](#-2-liste-de-concept-utile-)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.1 Imbalanced dataset](#21-imbalanced-dataset)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.2 Feature scaling](#22-features-scaling)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.3 Gradient descent](#23-gradient-descent)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.4 Loss or metric function](#24-loss-function-or-metric-function)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.5 Hyperparam√®tres](#25-hyperpam%C3%A8tre)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.6 Grid search](#26-grid-search)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.7 Learning curve](#27-learning-curve)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[2.8 Computational complexity](#28-computational-complexity)<br>\n",
    "\n",
    "\n",
    "\n",
    "## 1-Etapes d'un projet Data\n",
    "\n",
    "## 1.1-Bien d√©finir le probl√®me\n",
    "\n",
    "Bien que vous ayez un profil technique, la gestion de projets fera partie de votre m√©tier.\n",
    "\n",
    "Chaque projet doit d'avoir un probl√®me bien cadr√© sinon vous allez dans le mur!  \n",
    "Si vous n'√™tes pas en mesure de d√©finir le probl√®me, vous ne saurez pas √† quoi r√©pondre et donc vous ne pourrez rien d√©velopper ou alors vous r√©pondrez √† c√¥t√© dans **90%** des cas!\n",
    "\n",
    "Pour ce faire vous pouvez suivre les recommandations suivantes :\n",
    "\n",
    "##### Explorez la probl√©matique qui vous est pos√©e.\n",
    "Quel est le probl√®me?  \n",
    "Pourquoi le probl√®me existe, qu'est-ce que cela engendre?  \n",
    "Quelles sont les solutions pour y r√©pondre aujourd'hui?  \n",
    "Mesure-t-on le probl√®me aujourd'hui?    \n",
    "*S'il n'y a aucune donn√©es pour le mesurer, il sera compliqu√© pour vous de prouver a post√©riori que votre projet am√©liore quoi que ce soit.*  \n",
    "Qui est impact√© par ce probl√®me?\n",
    "\n",
    "##### Echangez, parler, identifier les personnes qui pourront r√©pondre √† vos questions\n",
    "Quand on d√©bute on peut avoir envie d'aller directement √† la solution mais d√©finir le probl√®me est g√©n√©ralement le fondement du projet.   \n",
    "Sauf si vous √™tes d√©ja expert dans le domaine d'application du projet, pensez √† interroger les personnes qui gravitent autour du probl√®me et ne vous lancez pas directement dans les donn√©es!\n",
    "\n",
    "Ce seront vos interpr√©teurs cl√©s et ils vous suivront le long du projet. **Plus t√¥t vous int√©grerez les utilisateurs finaux de votre projet plus vite vous verrez si vous √™tes √©loign√© ou non de leurs attentes**\n",
    "\n",
    "\n",
    "\n",
    ">A l'image d'un architecte, plus les plans de votre projet seront pr√©cis plus il sera facile de le d√©velopper apr√®s.\n",
    " Un probl√®me clairement sp√©cifi√© vous permettra de mieux d√©couper votre travail et vous gagnerez du temps par la suite\n",
    "\n",
    "#####  Synth√©tiser votre travail souvent\n",
    "\n",
    "A la fin de l'√©tape de d√©finition du probl√®me vous devriez √™tre capable de :\n",
    "\n",
    "- D√©finir le **PROBLEME** que vous r√©glerez et le **BESOIN** auquel il r√©pond\n",
    "- Mesurer avec des chiffres le probl√®me\n",
    "- Expliquer votre solution et ses impactes\n",
    "- D√©couper votre solution en plusieurs √©tapes\n",
    "\n",
    "<u>Synth√©tiser ces points dans un document et pr√©senter-le</u>\n",
    "\n",
    "\n",
    "##### Commencez petit\n",
    "\n",
    "Parfois, il vaut mieux prototyper rapidement et pr√©senter votre solution avant de vous lancer dans de grands d√©veloppements.\n",
    "Un prototype rapide √† d√©velopper  qu'on peut tester rapidement restera mieux qu'un projet de 2ans o√π on d√©veloppe dans son coin sans avoir de retour(parfois le pire est de travailler longtemps de son cot√© et se rendre compte que notre travail ne convient pas)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 1.2-Trouver les donn√©es\n",
    "\n",
    "Maintenant que vous avez un 'plan', vous savez comment r√©pondre th√©oriquement au probl√®me mais il va falloir se confronter √† la r√©alit√©.\n",
    "\n",
    "Vous allez devoir trouver les donn√©es dont vous avez besoin pour r√©pondre √† votre probl√©matique:\n",
    "\n",
    "**1** Lister intuitivement les donn√©es dont vous avez besoin  \n",
    "<br>\n",
    "**2** Trouver un interlocuteur ou un document vous expliquant o√π sont les donn√©es/ comment elles sont g√©n√©r√©es  \n",
    "<br>\n",
    "**3** Cr√©er vous un nouvel espace de travail( **un espace par projet**)  \n",
    "<br>\n",
    "**4** V√©rifier les **obligations l√©gales relatives √† vos donn√©es** (RGDP, Techniques, fuites de donn√©es, ...)  \n",
    "<br>\n",
    "**5** Demander des autorisations (si besoin)  \n",
    "<br>\n",
    "**6** Commencer √† regarder le type des donn√©es dont vous avez besoin (Image, texte, tabulaire, temporelle, g√©ographique,...)   \n",
    "<br>\n",
    "**7** Cr√©er un **code automatisable** pour r√©cup√©rer vos donn√©es  \n",
    "<br>\n",
    "**8** Structurer votre jeu de donn√©es pour que ce soit simple par la suite :\n",
    "- Format des donn√©es\n",
    "- Nom des colonnes\n",
    "- Restriction sur votre p√©rim√®tre\n",
    "   \n",
    "\n",
    "## 1.3-Explorer les donn√©es\n",
    "\n",
    "Dans cette partie vous allez essayer de faire ressortir les *insights* de vos donn√©es  \n",
    "üí° **Pensez automatisation, si vous rajoutez des nouvelles donn√©es vous ne devez pas recoder l'analyse**\n",
    "\n",
    "**1** Cr√©er une copie de votre dataset pour travailler dessus (diminuer le taille s'il est trop volumineux)\n",
    "<br>\n",
    "<br>\n",
    "**2** Pour de l'exploration jupyter notebook est tr√®s bien! (on l'oubliera pour le passage en production)  \n",
    "<br>\n",
    "**3** Analyser vos donn√©es de fa√ßon descriptive.\n",
    "> Un conseil, regarder du cot√© de [html report pandas](https://github.com/ydataai/pandas-profiling)\n",
    "\n",
    "**4** Modifier le type de vos donn√©es si n√©cessaire  \n",
    "<br>\n",
    "**5** Pour une analyse supervis√©e, identifier la variable cible (target)  \n",
    "<br>\n",
    "**6** Visualiser les donn√©es  \n",
    "<br>\n",
    "**7** Etudier les corr√©lations  \n",
    "<br>\n",
    "**8** R√©fl√©chir √† comment r√©soudre le probl√®me en tant qu'humain sans coder      \n",
    "&nbsp;&nbsp;&nbsp;Quelles informations utiliseriez-vous? Comment le feriez-vous?  \n",
    "&nbsp;&nbsp;&nbsp;Apr√®s l'avoir fait, essayer de transposer ca en code  \n",
    "**9** Commencer le *feature engineering* pour cr√©er des nouvelles features  \n",
    "<br>\n",
    "**10** Retourner √† l'√©tape 2 s'il manque des donn√©es  \n",
    "\n",
    "> Pensez √† Documenter vos trouvailles, documenter, documenter, documenter!\n",
    "\n",
    "## 1.4-Pr√©parer le dataset\n",
    "\n",
    "üí°Travailler sur une copie du dataset  \n",
    "üí°Ecrivez des functions et pas du code non r√©utilisable \n",
    "\n",
    "### Plan pour pr√©parer son dataset    \n",
    "\n",
    "- 1) **Data cleaning** (outliers, NA value, ...)  \n",
    "\n",
    "\n",
    "- 2) **Feature selection**(si besoin)  \n",
    "\n",
    "    - Etudes des corr√©lations\n",
    "    - Variables d'importances\n",
    "    - R√©gression p√©nalis√©e\n",
    "    - Stats descriptives\n",
    "\n",
    "\n",
    "- 3) **Feature engineering** adatp√© √† vos besoins  \n",
    "\n",
    "    - Discr√©tiser vos donn√©es continues\n",
    "    - Recoder variables cat√©gorielles\n",
    "    - Ajouter des transformations de features\n",
    "    - Agr√©ger des features  \n",
    "\n",
    "\n",
    "- 4) **Feature scaling** \n",
    "\n",
    "    - Standardiser ou normaliser vos features\n",
    "    \n",
    "    \n",
    "> Ce [bouquin](https://www.oreilly.com/library/view/feature-engineering-for/9781491953235/) est pas mal si ca vous int√©resse d'en savoir plus<br>\n",
    "> Un site pour la [Feature selection](https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/])\n",
    "\n",
    "\n",
    "## 1.5-Explorer des mod√®les et d√©terminer une short-list \n",
    "\n",
    "1) Entrainer des mod√®les avec les hyperparam√®tres par d√©faut  \n",
    "     *Des mod√®les avec des paradigmes diff√©rents (regressions, arbres, svm, neural net, xgboost,...*\n",
    "     \n",
    "     \n",
    "**2** Mesurer les performances de chaque mod√®le  \n",
    "&nbsp;&nbsp;&nbsp;*Utiliser une cross-validation avec n-fold*\n",
    "     \n",
    "     \n",
    "**3** Analyser les variables d'importances pour chaque mod√®le\n",
    "\n",
    "\n",
    "**4** Analyser les erreurs du mod√®le\n",
    "\n",
    "\n",
    "**5** R√©aliser une liste des features pertinents\n",
    "\n",
    "\n",
    "**6** Essayer de changer d'am√©liorer rapidement vos pr√©c√©dents mod√®les\n",
    "\n",
    "\n",
    "**7** Garder une liste des 3 meilleurs mod√®les\n",
    "\n",
    "## 1.6-Tuner les mod√®les\n",
    "\n",
    "üèÅ Vous allez maintenant utiliser l'ENSEMBLE de vos donn√©es pour obtenir le meilleur mod√®le possible\n",
    "\n",
    "**1** Tunez vos mod√®les en utilisant une cross validation\n",
    "- Par exp√©rience, je vous conseille de traiter votre feature engineering comme un hyperparam√®tre.\n",
    "  Surtout si vous n'√™tes pas s√ªr de votre strat√©gie (ie, imputation NA, r√©unification Data, ...)\n",
    "      \n",
    "- Random grid, search, bayesian grid search\n",
    "    \n",
    "**2** Si vos mod√®les offres des performances faibles, testez les [mod√®les ensemblistes](https://scikit-learn.org/stable/modules/ensemble.html)\n",
    "\n",
    "**3** Quand votre mod√®le est suffisament performant sur le **training test**, mesurer sa performance avec le **test set**\n",
    "\n",
    "## 1.7-Pr√©senter votre solution\n",
    "\n",
    "**1** Documentez votre projet  \n",
    "&nbsp;&nbsp;&nbsp;*Pensez bien √† expliquer les choix que vous avez faits*\n",
    "\n",
    "**2** Cr√©er une pr√©sentation sympa (pas de word SVP)  \n",
    "&nbsp;&nbsp;&nbsp;*Mettez en avant les informations importantes*\n",
    "     \n",
    "**3** Expliquer concr√®tement comment votre projet r√©pond au besoin business (besoin de d√©part)\n",
    "\n",
    "**4** Pensez √† comment vous allez vendre votre projet!  \n",
    "&nbsp;&nbsp;&nbsp;*Si vous n'√™tes pas dans une entreprise tech, il sera parfois compliqu√© de prouver que votre mod√®le est utile.*<br>\n",
    "&nbsp;&nbsp;&nbsp;*Faites de la com, soyez imaginatif*\n",
    "     \n",
    "\n",
    "## 1.8-Automatiser votre mod√®le, monitorer votre mod√®le et le maintenir\n",
    "\n",
    "**1** Pr√©parer votre code pour passer en production \n",
    "\n",
    "**2** Pr√©parer un monitoring de votre code\n",
    "\n",
    "- Suivre la performance de votre mod√®le (KPI)\n",
    "- Suivre que votre mod√®le s'excute bien\n",
    "- V√©rifier que le mod√®le ne se d√©grade pas\n",
    "- Mesurer qu'il n'y a pas de d√©rive sur vos donn√©es\n",
    "    \n",
    "**3** Faites r√©guli√®rement des points avec le business pour prouver que votre solution am√©liore la situation\n",
    "\n",
    "<center><h1> 2-Liste de concept utile </h1></center>\n",
    "\n",
    "## 2.1-Imbalanced dataset\n",
    "\n",
    "Le cas le plus commun de donn√©es d√©s√©quilibr√©es est une classification binaire.\n",
    "\n",
    "Prenons l'exemple d'une fraude √† la carte bancaire.  \n",
    "Nous avons un data set contenant 1 million d'op√©rations bancaires. La fraude √©tant un √©l√©ment rare (heuresement) notre data set ne contient que 10 000 fraudes pour 990 000 non fraudes.\n",
    "\n",
    "Si nous entrainons un mod√®le de machine learning pour une classification binaire sur ce projet, il sera incapable d'apprendre ce qu'est une fraude car nous ne lui pr√©senterons pas suffisamment d'exemple pour qu'il arrive √† d√©finir une fraude.\n",
    "\n",
    "Imaginons tout de m√™me que nous entrainions tout de m√™me un mod√®le logit sur ce dataset.  \n",
    "**Le mod√®le donne une accuracy de 89%** \n",
    "> Est-ce une bonne nouvelle, le mod√®le est-il pertinent?\n",
    "\n",
    "On aurait tendance √† dire oui car 89% de bonne pr√©diction semble √™tre une valeur √©lev√©e mais 89% est plus faible qu'une pr√©diction na√Øve...\n",
    "\n",
    "Un algo qui dirait syst√©matiquement qu'une op√©ration n'est pas une fraude aurait raison √† 99% du temps 99000/1000000.\n",
    "\n",
    "\n",
    "Si vous √™tes confront√© √† ce genre de probl√®me, vous pouvez utiliser les m√©thodes suivantes :\n",
    "\n",
    "- **Upsampling** : Augmenter l'√©v√©nement rare avec un tirage al√©atoire avec replacement\n",
    "- **Downsampling** : Diminuer l'√©v√©nement non rare en retirant des cas\n",
    "- **Oversampling** : Algorithme ROSE ou SMOTE cr√©ant artificiellement de nouveaux cas rares\n",
    "\n",
    "> Lien pour smote et rose https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\n",
    "\n",
    "\n",
    "\n",
    "## 2.2-Features scaling\n",
    "\n",
    "Le scaling feature (mettre vos donn√©es √† la m√™me √©chelle) permet d'exprimer diff√©rentes features avec diff√©rentes grandeurs num√©riques dans une m√™me unit√©s.\n",
    "\n",
    "\n",
    "Il exite 2 grandes familles pour le feature scaling :\n",
    "\n",
    "- La normalisation\n",
    "\n",
    "- La standardisation\n",
    "\n",
    "Les 2 permettent d'exprimer les colonnes num√©riques dans une m√™me unit√©s, am√©liorer le temps de calcul des mod√®les et pour certain mod√®le donner de meilleures performances.\n",
    "\n",
    "### Normalisation\n",
    "\n",
    "La normalisation est le fait de transformation vos features dans une √©chelle [0,1]. On l'appelle parfois *min-max scaling*.\n",
    "Sa formule est la suivante\n",
    "\n",
    "$X_{norm} = \\frac{X-X_{min}}{X_{max}-X_{min}}$\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#Exmple\n",
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
    "scaler = MinMaxScaler() \n",
    "print(scaler.fit_transform(data))\n",
    "```\n",
    "\n",
    "### Standardisation\n",
    "\n",
    "La standardisation est une technique qui permet quant √† elle de transformer nos colonnes en variable avec une moyenne de 0 et un √©cart type de 1.  \n",
    "Les colonnes transform√©es auront donc les m√™mes param√®tres de distribution.\n",
    "La standardisation pr√©sente des avantages quand il existe des outliers, comme on utilise pas la valeur Min et Max, la technique y est moins sensible!  \n",
    "\n",
    "$z = \\frac{X-\\mu}{\\sigma}$\n",
    "\n",
    "```python \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data = [[4, 8], [-5, 25], [4, 1], [9, 2.5]]\n",
    "scaler = StandardScaler()\n",
    "print(scaler.fit_transform(data))\n",
    "\n",
    "```\n",
    "\n",
    "> Article int√©ressant : https://towardsdatascience.com/normalization-vs-standardization-quantitative-analysis-a91e8a79cebf\n",
    "\n",
    "## 2.3-Gradient Descent\n",
    "\n",
    "Quand vous calculez les param√®tres de votre mod√®le vous avez 2 possibilit√©s :\n",
    "\n",
    "\n",
    "- Utiliser une r√©solution math√©matique pour obtenir la solution optimale (exemple, r√©solution MCO reg lin√©aire)  \n",
    "\n",
    "\n",
    "- Utiliser une r√©solution d'optimisation successive appell√©e **Descent de Gradient** qui va chercher it√©rativement les param√®tres qui minisent la fonction de co√ªt du mod√®le\n",
    "\n",
    "\n",
    "> Plus d'informations ici https://developers.google.com/machine-learning/crash-course/reducing-loss/an-iterative-approach\n",
    "\n",
    "\n",
    "Concr√®tement vous commencez avec un param√®tr $\\theta$ donn√© et vous allez le faire varier it√©rativement en fonction de la valeur de sa d√©riv√©e.  \n",
    "On peut l'observer graphiquement sur le graphique N¬∞1\n",
    "\n",
    "\n",
    "\n",
    "<u>Graphique N¬∞1 :Descente de gradient</u>\n",
    "\n",
    "<img src=\"https://github.com/Roulitoo/cours_iae/blob/master/00_intro/img/descente_gradient_1.png\" alt=\"fig_1_descente_gradient.png\" style=\"width:600px;\"/>\n",
    "\n",
    "Chaque point rouge repr√©sente une it√©ration de descente de gradient et converge vers le minimum global de la fonction de perte.  \n",
    "Nous obtenons en ce point pour un param√®tre $\\theta$ dont la valeur minimise notre fonction de perte. \n",
    "\n",
    "\n",
    "<u>Graphique N¬∞2 :Descente de gradient, learning rate trop faible</u>\n",
    "\n",
    "<img src=\"https://github.com/Roulitoo/cours_iae/blob/master/00_intro/img/descente_gradient_2.png\" alt=\"fig_2_descente_gradient.png\" style=\"width:600px;\"/>\n",
    "\n",
    "Il est important que la taille du 'saut' de mise √† jour de la valeur de votre param√®tre $\\theta$ ne soit pas trop faible.\n",
    "On appellera le param√®tre qui contr√¥le le 'saut' **LEARNING RATE**.  \n",
    "Si celui-ci est trop faible vos 'sauts' seront petits, il faudra beaucoup d'it√©rations avant de trouver le param√®tre optimal.\n",
    "\n",
    "\n",
    "<u>Graphique N¬∞3 :Descente de gradient, learning rate trop haut</u>\n",
    "\n",
    "<img src=\"https://github.com/Roulitoo/cours_iae/blob/master/00_intro/img/descente_gradient_3.png\" alt=\"fig_3_descente_gradient.png\" style=\"width:600px;\"/>\n",
    "\n",
    "A l'inverse si le *LEARNING RATE* est trop √©lev√© vous pourriez ne jamais trouver l'optimal de votre fonction.  \n",
    "Le calcul divergera et ne trouvera jamais de minimum local.\n",
    "\n",
    "Un peu de math pour comprendre la descente de gradientüòÄ.\n",
    "C'est un concept fondamental pour les algorithmes de machine learning!!\n",
    "\n",
    "Exemple de descente de gradient avec **fonction de co√ªt MSE** pour un mod√®le lin√©aire:\n",
    "\n",
    "On d√©finit une fonction lin√©aire avec un vecteur de param√®tre $\\theta$  \n",
    "$\\widehat{y} = \\theta_0 + \\theta_1x1+...+\\theta_nxn$\n",
    "\n",
    "o√π  :\n",
    "\n",
    "- $\\theta_0 : Biais\\space du\\space modele $\n",
    "- $\\theta_n : Param√®tre \\space du \\space mod√®le$\n",
    "- $\\widehat{y} : Valeur\\space pr√©dite$\n",
    "- $n : Nombre \\space de \\space features$\n",
    "\n",
    "\n",
    "Au format vectoriel nous avons l'√©quation suivante :\n",
    "\n",
    "$\\widehat{y} = h_\\theta(x) = \\theta.X$\n",
    "\n",
    "On d√©finit la fonction de perte de ce mod√®le comme :\n",
    "\n",
    "$MSE(X, h_\\theta) = \\frac{1}{N}\\sum_{i=1}^N (y_i-\\widehat{y_i})¬≤$\n",
    "\n",
    "Pour impl√©menter la descente de gradient, vous devez calculer le gradient de la fonction de co√ªt MSE en fonction de ses param√®tres $\\theta$\n",
    "On doit donc calculer toutes les d√©riv√©es partielles de la fonction MSE\n",
    "\n",
    "$\\frac{\\partial}{\\partial \\theta_j} MSE(\\theta) = \\frac{2}{N}\\sum_{i=1}^N (\\theta^Tx^{(i)}-y^{(i)})x^{(i)}_j$\n",
    "  \n",
    "ou au format vectoriel\n",
    "\n",
    "$$\\nabla_\\theta MSE(\\theta) = \\begin{pmatrix}  \\frac{\\partial}{\\partial \\theta_0} \\\\ \\frac{\\partial}{\\partial \\theta_1} \\\\ . \\\\frac{\\partial}{\\partial \\theta_n}  \\end{pmatrix} =\\frac{2}{N}X^T (X\\theta-y)$$ \n",
    "\n",
    "Une fois que vous avez le vecteur de descente de gradient, vous devez simplement mettre √† jour vos param√®tres $\\theta$ jusqu'√† atteindre le minimum de votre fonction.\n",
    "\n",
    "$\\theta^{(next)} = \\theta - \\eta\\nabla_\\theta MSE(\\theta)$\n",
    "\n",
    "#### Exemple descente de gradient\n",
    "Un exemple en dimension 1 pour mieux comprendre üòÄ\n",
    "\n",
    "Nous avons une fonction  $f(x) = 3x^2 -2x +5$ et nous souhaitons minimiser cette fonction\n",
    "\n",
    "<u>Graphique N¬∞4 :Exemple descente de gradient</u>\n",
    "\n",
    "<img src=\"https://github.com/Roulitoo/cours_iae/blob/master/00_intro/img/exemple_grad_1D_4.png\" alt=\"fonction_exemple_4.png\" style=\"width:500px;\"/>\n",
    "\n",
    "**Etape 1 : On calcule son vecteur gradient **\n",
    "\n",
    "En dimension le vecteur est de taille 1, donc on calcule uniquement une d√©riv√©e\n",
    "\n",
    "$f'(x) = 6x -2x$\n",
    " \n",
    "**Etape 2 : On initialise une valeur de $x$ par d√©faut et une valeur pour le learning rate**\n",
    "\n",
    "On pose $x_0 = 5$ et $\\eta = 0.05$\n",
    "\n",
    "La formule pour les √©tapes de descente de gradient en D1 est donc :\n",
    "$x_{n+1} = x_n -\\eta*f'(x_n)$\n",
    "\n",
    "**Etape 3 : It√©ration sucessive descente de gradient**\n",
    "\n",
    "<u>Graphique N¬∞5 :Exemple descente de gradient</u>\n",
    "\n",
    "<img src=\"https://github.com/Roulitoo/cours_iae/blob/master/00_intro/img/descente_grad_exemple_5.png\" alt=\"fonction_exemple_descente_grad_5.png\" style=\"width:500px;\"/>\n",
    "\n",
    "\n",
    "Successivement la valeur de $\\theta$ se rapproche de la valeur de $x=\\frac{1}{3}$ qui minise la fonction.\n",
    "Quand vous utiliserez l'hyperparam√®tre **learning rate** pour un algo de machine learning c'est exactement ca qui se passera en back.\n",
    "\n",
    "> Vous savez maintenant ce qu'est la descente de gradient, bravo !\n",
    "\n",
    "## 2.4-LOSS function or Metric function?\n",
    "\n",
    "Les 2 termes sont souvent confondus dans le domaine du machine learning mais il repr√©sente pourtant 2 concepts bien diff√©rents.\n",
    "\n",
    "#### Loss function\n",
    "La *loss function* ou *cost function* est utilis√©e pour entrainer notre mod√®le de ML et c'est la fonction que nous allons chercher √† optimiser (minimiser ou maximiser) les param√®tres du mod√®le.  \n",
    "\n",
    "Globalement elle donne l'√©cart entre la qualit√© de notre pr√©diction et la valeur de r√©f√©rence.\n",
    "\n",
    "Exemple : \n",
    "\n",
    "- Logistic sigmoid\n",
    "- Mean squared error\n",
    "- Cross-Entropy\n",
    "- Hinge loss\n",
    "- etc\n",
    "\n",
    "\n",
    "\n",
    "#### Metric function\n",
    "\n",
    "La *Metric function* est quant √† lui un crit√®re a post√©riori qui permet d'√©valuer la qualit√©/performance du mod√®le. C'est un quantifieur permettant au cr√©ateur du mod√®le d'√©valuer si son mod√®le est bon ou mauvais.\n",
    "\n",
    "Exemple : \n",
    "\n",
    "- Accuracy\n",
    "- F1 Score\n",
    "- Recall\n",
    "- etc\n",
    "\n",
    "\n",
    "#### Spoiler\n",
    "\n",
    "Certaines $Loss function$ sont aussi des $Metric function$, c'est quasi tout le temps le cas pour les mod√®les de r√©gression!\n",
    "\n",
    ">Toutes les loss function de scikit : https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "## 2.5-Hyperpam√®tre\n",
    "\n",
    "Il ne faut pas confondre les param√®tres d'un mod√®le qui d√©pendent directement des donn√©es et sont calcul√©s analytiquement avec les hyperparam√®tres.\n",
    "\n",
    "Tous les mod√®les de machine learning n'en poss√®dent pas. Par exemple la r√©gression lin√©aire ne poss√®de aucun hyperparam√®tre, l'ensemble de ses param√®tres est calcul√© √† partir des donn√©es.\n",
    "\n",
    "En revanche, les mod√®les de machine learning complexes en poss√®dent √©normement. Ils permettent de contr√¥ler l'apprentissage du mod√®le et impactent donc directement les param√®tres du mod√®le.\n",
    "Leur valeur n'est pas connue √† l'avance et la seule fa√ßon de trouver la combinaison optimale est de faire varier leur valeur tout en observant l'impact sur la fonction de perte.\n",
    "\n",
    "\n",
    "Exemple :\n",
    "\n",
    "- Le learning rate \n",
    "- Regularization parameter (ridge, lasso,...)\n",
    "- Max depth, Max features ( random forest, ...)\n",
    "\n",
    ">Pour approndir\n",
    ">https://towardsdatascience.com/parameters-and-hyperparameters-aa609601a9ac\n",
    "\n",
    "\n",
    "## 2.6-Grid search\n",
    "\n",
    "Le moyen le plus simple de trouver les valeurs de vos hyperparam√®tres qui maximise ou minimise ou votre *loss function* est de r√©aliser un *grid search*.\n",
    "\n",
    "C‚Äôest une m√©thode d‚Äôoptimisation (hyperparameter optimization) qui va nous permettre de tester une s√©rie de param√®tres et de comparer les performances pour en d√©duire le meilleur param√©trage.\n",
    "On d√©finit une plage de valeur possible pour nos hyperparam√®tres et toutes les combinaisons seront test√©es pour voir lesquelles donnent le meilleur mod√®le.\n",
    "\n",
    "\n",
    "\n",
    "Il existe 3 types de grid search :\n",
    "\n",
    "- **Grid search** : On d√©finit manuellement une grille de combinaison des hyperparam√®tres. Plus vous aurez de l'exp√©rience plus il sera facile de d√©finir les hyperparam√®tres et donc r√©duire l'espace de la grille.\n",
    "\n",
    "\n",
    "- **Random Grid search** : On d√©finit une grille dans lequel les hyperparam√®tres prennent leur valeur dans un espace que nous lui fournissons. Dans l'ensemble de cet espace, il va chercher les hyperparam√®tres qui donne le meilleu r√©sultat.\n",
    "\n",
    "On peut voir graphiquement le r√©sultat des 2 approches.\n",
    "\n",
    "<u>Graphique N¬∞6 :Visualisation grid search avec 2 hyperparam√®tres</u>\n",
    "\n",
    "<img src=\"https://github.com/Roulitoo/cours_iae/blob/master/00_intro/img/grid_search_6.png\" alt=\"gris_search_6.png\" style=\"width:1000px;\"/>\n",
    "\n",
    "Le random search donne g√©n√©ralement de meilleure performance mais il est aussi beaucoup plus couteux en temps de calcul... A vous d'arbitrer.\n",
    "\n",
    "- **Bayesian Grid search** :  Cette m√©thode diff√©re des autres car elle va s√©lectionner les hyperparam√®tres √† chaque entrainement de mod√®le conditionnelement aux r√©sultats du pr√©c√©dent. Th√©oriquement la combinaison de meilleur param√®tre sera trouv√© plus vite que pour les 2 pr√©c√©dents et elle retira automatiquement les espaces o√π la combinaison d'hyperparam√®tre est mauvaise. Comme pour les 2 autres, il faut fournir au d√©part l'espace o√π tester les hyperparam√®tres.\n",
    "\n",
    "\n",
    "\n",
    "Pour impl√©menter ces m√©thodes en python, vous pouvez utiliser les codes suivants :\n",
    "\n",
    "```python\n",
    "#Import function\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Define grid\n",
    "param_grid = {\n",
    "    \"max_samples\": [0.2, 0.3, 0.4, 0.4, 0.1],\n",
    "    \"max_features\": [1, 2],\n",
    "    \"max_depth\": [ 4, 20,] \n",
    "            }\n",
    "#Grid\n",
    "reg_grid = GridSearchCV(RandomForestClassifier(),\n",
    "                        param_grid=param_grid,\n",
    "                        cv=5,\n",
    "                        n_jobs=4, \n",
    "                        scoring='accuracy'\n",
    "                       )\n",
    "\n",
    "#Fit model\n",
    "model_grid = reg_grid.fit(X, y)\n",
    "#get best estimator\n",
    "model_grid.best_estimator_\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "#### Random search\n",
    "\n",
    "```python \n",
    "#Import function\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "#Define grid\n",
    "param_grid = {\n",
    "    \"max_samples\": uniform(1e-2, 0.5),\n",
    "    \"max_features\": randint(1,2),\n",
    "    \"max_depth\": randint(4, 400) \n",
    "}\n",
    "\n",
    "# Random\n",
    "reg_rand = RandomizedSearchCV(RandomForestClassifier(),\n",
    "                         param_distributions=param_grid,\n",
    "                         cv=5,\n",
    "                         n_jobs=4,\n",
    "                         scoring='accuracy',\n",
    "                         random_state=42)\n",
    "#Fit model\n",
    "model_rand = reg_rand.fit(X, y)\n",
    "\n",
    "#Print best estimator\n",
    "print(model_rand.best_estimator_)\n",
    "\n",
    "```\n",
    "#### Bayesian search\n",
    "\n",
    "```python \n",
    "#! pip install scikit-optimize\n",
    "from skopt import BayesSearchCV\n",
    "# parameter ranges are specified by one of below\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "#Real : Nombre r√©el\n",
    "#Categorial : data cat√©gorielle, exemple 'bleu', 'rouge'\n",
    "#Integer : ...\n",
    "\n",
    "#Define grid\n",
    "param_grid = {\n",
    "    \"max_samples\": Real(1e-2, 0.5),\n",
    "    \"max_features\": Integer(1,2),\n",
    "    \"max_depth\": Integer(4, 400) \n",
    "}\n",
    "#grid\n",
    "reg_bay = BayesSearchCV(estimator=RandomForestClassifier(),\n",
    "                    search_spaces=param_grid,\n",
    "                    cv=5,\n",
    "                    n_jobs=8,\n",
    "                    scoring='accuracy',\n",
    "                    random_state=42)\n",
    "#Fit the data\n",
    "model_bay = reg_bay.fit(X, y)\n",
    "#Meilleur estimateur\n",
    "print(model_bay.best_estimator_)\n",
    "\n",
    "```\n",
    "\n",
    "> Article int√©ressant sur le grid search et random search  \n",
    ">https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/  \n",
    "> Comparaison 3 types de grid search, article  \n",
    ">https://towardsdatascience.com/bayesian-optimization-for-hyperparameter-tuning-how-and-why-655b0ee0b399  \n",
    "> Doc impl√©mentation bayesian grid search  \n",
    ">https://scikit-optimize.github.io/stable/index.html\n",
    "\n",
    "## 2.7-Learning curve\n",
    "\n",
    "En mod√©lisation on dit souvent que \"plus on a de data plus le mod√®le sera pr√©cis\". Cette affirmation est vraie, augmenter le nombre de data am√©liore g√©n√©ralement les performance des mod√®les.<br>\n",
    "<br>\n",
    "Cependant, il existe une quantit√© de data √† partir duquel le mod√®le arr√™te d'apprendre. Autrement dit rajouter des donn√©es ne sert √† rien √† part augmenter le temps de calcul!\n",
    "Cela peut venir du fait qu'il existe un parttern simple dans vos donn√©es et le mod√®le apprend tr√®s vite ou malheuresement que vos donn√©es ne permettent de pas d'expliquer le ph√©nom√®ne √©tudi√©.\n",
    "\n",
    "Une mani√®re de visualiser cette relation quantit√© de data et performance du mod√®le est d'utiliser des learning curve.\n",
    "\n",
    "On it√®re plusieurs mod√©lisations du m√™me mod√®le sans faire varier les hyperparam√®tres mais on entraine syst√©matiquement avec un peu plus de data pour voir l'impact sur la qualit√© du mod√®le.\n",
    "\n",
    "G√©n√©ralement on repr√©sente cette technique avec un graphique qui ressemble √† celui ci-dessous :\n",
    "\n",
    "\n",
    "<u>Graphique N¬∞7 :Visualisation learning curve</u>\n",
    "\n",
    "<img src=\"https://github.com/Roulitoo/cours_iae/blob/master/00_intro/img/learning_curve_7.png\" alt=\"learning_curve_7.png\" style=\"width:600px;\"/>\n",
    "\n",
    "Pour impl√©menter ce type de graphique nous utilisons encore une fois [sklearn](https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html)\n",
    "\n",
    "```python\n",
    "#Ploting learnin curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#Split in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=1)\n",
    "#Model\n",
    "lr = LogisticRegression(max_iter = 1000 , random_state= 42)\n",
    "\n",
    "# Use learning curve to get training and test scores along with train sizes\n",
    "#Learning curve function with train_sizes = d√©coupage du dataset en 10 de 10% √† 100%\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=lr, \n",
    "                                                        X=X_train, \n",
    "                                                        y=y_train,\n",
    "                                                        cv=10, \n",
    "                                                        train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "                                                       )\n",
    "\n",
    "#\n",
    "# Trop de fluctuation dans le mod√®le, on calcule la moyenne des m√©triques\n",
    "#\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "#\n",
    "# Plot the learning curve\n",
    "#\n",
    "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training Accuracy')\n",
    "plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
    "plt.plot(train_sizes, test_mean, color='green', marker='+', markersize=5, linestyle='--', label='Validation Accuracy')\n",
    "plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Training Data Size')\n",
    "plt.ylabel('Model accuracy')\n",
    "plt.grid()\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "## 2.8-Computational complexity \n",
    "\n",
    "En machine learning, le $computational complexity$ ou complexit√© de l'algorithme est le montant de ressources n√©cessaires pour utiliser un mod√®le.\n",
    "On distingue le temps d'entrainement d'un mod√®le et le temps de pr√©diction d'un mod√®le d√©ja entrain√©.\n",
    "\n",
    "A titre d'exemple.\n",
    "\n",
    "La r√©gression lin√©aire impl√©ment√©e avec sklearn poss√®de une complexit√© de $O(n_{samples} n^2_{features})$.\n",
    "Si on double le nombre de lignes et de colonnes du dataset, on augmente alors de $2.2^2 = 8$  le temps de calcul. Un temps de calcul alors 8 fois plus long.\n",
    "\n",
    "En revanche la pr√©diction ne d√©pend que du nombre de colonnes $O(n_{features})$\n",
    "\n",
    "> Tableau comparaison model complexity :https://www.thekerneltrip.com/machine/learning/computational-complexity-learning-algorithms/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
