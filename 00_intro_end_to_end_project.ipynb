{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Un projet Data en 8 √©tapes</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Bien d√©finir le probl√®me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien que vous ayez un profil technique, la gestion de projet fera partie de votre m√©tier.\n",
    "\n",
    "Chaque projet se doit d'avoir un probl√®me bien cadr√© sinon vous allez dans le mur!  \n",
    "Si vous n'√™tes pas en mesure de d√©finir le probl√®me, vous ne saurez pas √† quoi r√©pondre et donc vous ne pourrez rien d√©velopper ou alors vous r√©pondrez √† cot√© dans **90%** des cas!\n",
    "\n",
    "Pour ce faire vous pouvez suivre les recommandations suivantes :\n",
    "\n",
    "##### Explorez la probl√©matique qui vous est pos√©.\n",
    "Quel est le probl√®me?  \n",
    "Pourquoi le probl√®me existe, qu'est ce que cela engendre?  \n",
    "Quelles sont les solutions pour y r√©pondre aujourd'hui?  \n",
    "Mesure-t-on le probl√®me aujourd'hui?    \n",
    "*S'il n'y a aucunes donn√©es pour le mesurer, il sera compliqu√© pour vous de prouver √† post√©riori que votre projet am√©liore quoique ce soit.*  \n",
    " Qui est impact√© par ce probl√®me?\n",
    "\n",
    "##### Echangez, parler, identifier les personnes qui pourront r√©pondre √† vos questions\n",
    "Quant on d√©bute on peut avoir envie d'aller directement √† la solution mais d√©finir le probl√®me est g√©n√©ralement le fondement du projet.   \n",
    "Sauf si vous √™tes d√©ja expert dans le domaine d'application du projet, pensez √† int√©roger les personnes qui gravitent autour du probl√®me et ne vous lancez pas directement dans les donn√©es!\n",
    "\n",
    "Ce seront vos interpr√©teurs cl√©s et ils vous suivront le long du projet. **Plut√¥t vous int√©gregrer les utilisateurs finaux de votre projet plus vite vous verrez si vous √™tes √©loign√© ou non de leurs attentes**\n",
    "\n",
    "\n",
    "\n",
    ">A l'image d'un architecte, plus les plans de votre projet seront pr√©cis plus il sera facile de le d√©velopper apr√®s.\n",
    " Un probl√®me clairement sp√©cifier vous permettra de mieux d√©couper votre travail et vous gagnerez du temps par la suite\n",
    "\n",
    "#####  Synth√©tiser votre travail souvent\n",
    "\n",
    "A la fin de l'√©tape de d√©finition du probl√®me vous devriez √™tre capable de :\n",
    "\n",
    "- D√©finir le **PROBLEME** que vous r√©glerez et le **BESOIN** auquel il r√©pond\n",
    "- Mesurer avec des chiffres le probl√®me\n",
    "- Expliquer votre solution et ses impactes\n",
    "- D√©couper votre solution en plusieurs √©tapes\n",
    "\n",
    "Synth√®tiser ces points dans un document et pr√©senter le\n",
    "\n",
    "\n",
    "##### Commencez petit\n",
    "\n",
    "Parfois, il vaut mieux prototyper rapidement et pr√©senter votre solution avant de vous lancer dans de grand d√©veloppement.\n",
    "Un prototype rapide √† d√©velopper  qu'on peut tester rapidement restera mieux qu'un projet de 2ans o√π on d√©veloppe dans son coin sans avoir de retour(parfois le pire est de travailler longtemps de son cot√© et se rendre compte que notre travail ne convient pas)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Trouver les donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que vous avez un 'plan', vous savez comment r√©pondre th√©oriquement au probl√®me mais il va falloir se confronter √† la r√©alit√©.\n",
    "\n",
    "Vous allez devoir trouver les donn√©es dont vous avez besoin pour r√©pondre √† votre probl√®matique:\n",
    "\n",
    "**1** Lister intuitivement les donn√©es dont vous avez besoin  \n",
    "**2** Trouver un interlocteur ou un document vous explicant o√π sont les donn√©es/ comment elles sont g√©n√©r√©es  \n",
    "**3** Cr√©er vous un nouvel espace de travail( **un espace par projet**)  \n",
    "**4** V√©rifier les **obligations l√©gales relatives √† vos donn√©es** (RGDP, Techniques, fuites de donn√©es, ...)  \n",
    "**5** Demander des autorisations (si besoin)  \n",
    "**6** Commencer √† regarder le type des donn√©es dont vous avez besoin (Image, texte, tabulaire, temporelle, g√©ographique,...)   \n",
    "**7** Cr√©er un **code automatisable** pour r√©cup√©rer vos donn√©es  \n",
    "**8** Structurer votre jeu de donn√©es pour que ce soit simple par la suite :\n",
    "- Format des donn√©es\n",
    "- Nom des colonnes\n",
    "- Restriction sur votre p√©rim√®tre\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-Explorer les donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie vous allez essayer de faire ressortir les *insights* de vos donn√©es  \n",
    "üí° **Pensez automatisation, si vous rajoutez des nouvelles donn√©es vous ne devez pas recoder l'analyse**\n",
    "\n",
    "1 Cr√©er une copie de votre dataset pour travailler dessus (diminuer le taille si il est trop volumineux)  \n",
    "2 Pour de l'exploration jupyter notebook est tr√®s bien! (on l'oubliera pour le passage en production)  \n",
    "3 Analyser vos donn√©es de fa√ßon descripive\n",
    "> Un conseil, regarder du cot√© de [html report pandas](https://github.com/ydataai/pandas-profiling)\n",
    "\n",
    "4 Modifiez le type de vos donn√©es si n√©cessaire  \n",
    "5 Pour une analyse supervis√©e, identifier la variable cible (target)  \n",
    "6 Visualisez les donn√©es  \n",
    "7 Etudiez les corr√©lations  \n",
    "8 R√©fl√©chissez √† comment vous pourriez le r√©soudre le probl√®me en tant que humain sans coder      \n",
    "  Quelles informations utiliseriez-vous? Comment le feriez-vous?  \n",
    "  Apr√®s l'avoir fait, essayer de transposer ca en code  \n",
    "9 Commencez votre *feature engineering* pour cr√©er des nouvelles features  \n",
    "10 Retournez √† l'√©tape 2 s'il vous manque des donn√©es  \n",
    "\n",
    "> Pensez √† Documenter vos trouvailles, documenter, documenter, documenter!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-Pr√©parer le dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí°Travailler sur une copie du data set  \n",
    "üí°Ecrivez des functions et pas du code non r√©utilisable car \n",
    "\n",
    "##### Plan pour pr√©parer son dataset    \n",
    "\n",
    "- 1) **Data cleaning** (outliers, NA value, ...)  \n",
    "\n",
    "\n",
    "- 2) **Feature selection**(si besoin)  \n",
    "\n",
    "    - Etudes des corr√©lations\n",
    "    - Variable d'importances\n",
    "    - M√©thode de Shapley\n",
    "    - Stats descriptives\n",
    "\n",
    "\n",
    "- 3) **Feature engineering** adatp√© √† vos besoins  \n",
    "\n",
    "    - Discretiser vos donn√©es continues\n",
    "    - Recoder variables cat√©gorielles\n",
    "    - Ajouter des transformations de features\n",
    "    - Aggr√©ger des features  \n",
    "\n",
    "\n",
    "- 4) **Feature scaling** \n",
    "\n",
    "    - Standardiser ou normaliser vos features\n",
    "    \n",
    "    \n",
    "> Ce [bouquin](https://www.oreilly.com/library/view/feature-engineering-for/9781491953235/) est pas mal si ca vous int√©resse d'en savoir plus\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Explorer des mod√®les et d√©terminer une short-list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1) Entrainer des mod√®les avec les hyperparam√®tres par d√©faut  \n",
    "     *Des mod√®les avec des paradigmes diff√©rents (regressions, arbres, svm, neural net, xgboost,...*\n",
    "     \n",
    "     \n",
    "- 2) Mesurer les performances de chaque mod√®le  \n",
    "     *Utiliser une cross-validation avec n-fold*\n",
    "     \n",
    "     \n",
    "- 3) Analyser les variables d'importances pour chaque mod√®les\n",
    "\n",
    "\n",
    "- 4) Analyser les erreurs du mod√®les\n",
    "\n",
    "\n",
    "- 5) R√©aliser une liste des features pertinents\n",
    "\n",
    "\n",
    "- 6) Essayer de changer d'am√©liorer rapidement vos pr√©c√©dents mod√®les\n",
    "\n",
    "\n",
    "- 7) Garder une liste des 3 meilleurs mod√®les"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6- Tuner les mod√®les"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Vous allez maintenant utilisez l'ENSEMBLE des vos donn√©es pour obtenir le meilleur mod√®le possible\n",
    "\n",
    "- 1) Tunez vos mod√®les en utilisant une crossvalidation\n",
    "\n",
    "    - Par exp√©rience, je vous conseil de traiter votre feature engineering comme un hyperparam√®tre.\n",
    "      Surtout si vous n'√™tes pas s√ªr de votre strat√©gie (ie, imputation NA, r√©unification Data, ...)\n",
    "      \n",
    "    - Random grid, search, bayesian grid search\n",
    "    \n",
    "- 2) Si vos mod√®les offres des performances faibles, testez les mod√®les ensemblistes\n",
    "\n",
    "- 3) Quand votre mod√®le est suffisament performant sur le training test, mesurer sa performance avec le test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Pr√©senter votre solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1) Documentez votre projet\n",
    "     *Pensez bien √† expliquer les choix que vous avez fait*\n",
    "\n",
    "- 2) Cr√©er une pr√©sentation sympa (pas de word SVP)\n",
    "     *Mettez en avant les informations importantes*\n",
    "     \n",
    "- 3) Expliquer concr√®tement comment votre projet r√©pond au besoin business (besoin de d√©part)\n",
    "\n",
    "- 4) Pensez √† comment vous aller vendre votre projet!\n",
    "     Si vous n'√™tes pas dans une entreprise tech, il sera parfois compliqu√© de prouver que votre mod√®le est utile.\n",
    "     Faites de la com, soyez imaginatif\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Automatiser votre mod√®le, monitorer votre mod√®le et maintenir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1) Pr√©parer votre code pour passer en production \n",
    "\n",
    "- 2) Pr√©parer un monitoring de votre code\n",
    "\n",
    "    - Suivre la performance de votre mod√®le (KPI)\n",
    "    - Suivre que votre mod√®le s'excute bien\n",
    "    - V√©rifier que le mod√®le ne se d√©gragde pas\n",
    "    - Mesurer qu'il n'y a pas de d√©rive sur vos donn√©es\n",
    "    \n",
    " - 3) Faites r√©guli√®rement des points avec le business pour prouver que votre solution am√©liore la situation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept utile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le cas le plus comment de donn√©es d√©siquilibr√©e est une classification binaire.\n",
    "\n",
    "Prenons l'exemple d'un fraude √† la carte bancaire.  \n",
    "Nous avons un data set contenant 1 million d'op√©ration bancaire. La fraude √©tant un √©l√©ment rare (heuresement) notre data set ne contient que 10 000 fraude pour 990 000 non fraude.\n",
    "\n",
    "Si nous entrainons un mod√®le de machine learning pour une classifcation binaire sur ce projet, il sera incapable d'apprendre ce qu'est une fraude car nous ne lui pr√©senterons pas suffisament d'exemple pour qu'il arrive √† d√©finir une fraude.\n",
    "\n",
    "Imaginons tout de m√™me que nous entrainions tout de m√™me un mod√®le logit sur ce data set.  \n",
    "**Le mod√®le donne une accuracy de 89%** \n",
    "> Est-ce une bonne nouvelle, le mod√®le est-il pertinent?\n",
    "\n",
    "On aurait tendance √† dire oui car 89% de bonne pr√©diction semble √™tre une valeure √©lev√©e mais 89% est plus faible qu'une pr√©diction na√Øve...\n",
    "\n",
    "Si on cr√©er un algo qui dit syst√©matiquement qu'un op√©ration n'est pas une fraude il aura raison √† 99% du temps 99000/1000000.\n",
    "\n",
    "\n",
    "Si vous √™tes confronter √† ce genre de probl√®me, vous pouvez utiliser les m√©thodos suivantes :\n",
    "\n",
    "- Upsampling : Augmenter le nombre de l'√©v√©nement rare avec un tirage al√©atoire avec replacement\n",
    "- Downsampling : Diminuer le nombre de l'√©v√©nement non rare en retirant des cas\n",
    "- Oversampling : Algorithme ROSE ou SMOTE cr√©ant artificielment de nouveaux cas rare\n",
    "\n",
    "> Lien pour smote et rose https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le scaling feature (mettre vos donn√©es √† la m√™me √©chelle) permet d'exprimer diff√©rentes features avec diff√©rentes grandeurs num√©riques dans une m√™me unit√©s.\n",
    "\n",
    "\n",
    "Il exite 2 grandes familles pour le feature scaling :\n",
    "\n",
    "- La normalisation\n",
    "\n",
    "- La standardisation\n",
    "\n",
    "Les 2 permettent d'exprimer les colonnes num√©riques dans une m√™me unit√©s, am√©liorer le temps de calcul des mod√®les et pour certains mod√®les avec de meilleur performance.\n",
    "\n",
    "### Normalisation\n",
    "\n",
    "La normalisation est le fait de transformation vos features dans une √©chelle [0,1]. On l'appelle parfois *min-max scaling*.\n",
    "Sa formule est la suivante\n",
    "\n",
    "$X_{norm} = \\frac{X-X_{min}}{X_{max}-X_{min}}$\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#Exmple\n",
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
    "scaler = MinMaxScaler() \n",
    "print(scaler.fit_transform(data))\n",
    "```\n",
    "\n",
    "### Standardisation\n",
    "\n",
    "La standardisation est une technique qui permet quant √† elle de transformer nos colonnes en variable avec une moyenne de 0 et un √©cart type de 1. Les colonnes transform√©es auront donc les m√™mes param√®tres de distribution.\n",
    "La standardisation pr√©sente des avantages quand il existe des outliers, comme on utilise pas la valeur min et max, la technique y est moins sensible!  \n",
    "\n",
    "$z = \\frac{X-\\mu}{\\sigma}$\n",
    "\n",
    "```python \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data = [[4, 8], [-5, 25], [4, 1], [9, 2.5]]\n",
    "scaler = StandardScaler()\n",
    "print(scaler.fit_transform(data))\n",
    "\n",
    "```\n",
    "\n",
    "> Article int√©ressant : https://towardsdatascience.com/normalization-vs-standardization-quantitative-analysis-a91e8a79cebf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "\n",
    "Quand vous calculez les param√®tres de votre mod√®les vous avez 2 possibilit√©s :\n",
    "\n",
    "\n",
    "- Utiliser une r√©solution math√©matique pour obtenir la solution optimale (exemple, r√©solution MCO reg lin√©aire)  \n",
    "\n",
    "*Equation normale*\n",
    "\n",
    "- Utiliser une r√©solution d'optimitsation successive appell√©e **Descent de Gradient** qui va chercher it√©rativement les param√®tres qui minise la fonction de co√ªt du mod√®le\n",
    "\n",
    "\n",
    "> Plus d'information ici https://developers.google.com/machine-learning/crash-course/reducing-loss/an-iterative-approach\n",
    "\n",
    "\n",
    "Concr√©tement vous commencez avec un param√®tr $\\theta$ donn√© et vous allez le faire varier it√©rativement en fonction de la valeur de sa d√©riv√©e.  \n",
    "On peut l'observer graphiquement sur le graphique N¬∞1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Graphique N¬∞1 :Descente de gradient</u>\n",
    "<img src=\"https://raw.githubusercontent.com/Roulitoo/cours_iae/master/00_intro/img/descente_gradient_1.png?token=GHSAT0AAAAAABZOBGASQJQ5WDKPI3YBYA3IY3CYWCA\" alt=\"fig_2_intuition_svm.png\" style=\"width:600px;\"/>\n",
    "\n",
    "Chaque point rouge repr√©sente une it√©ration de descente de gradient et converge vers le minimun global de la fonction de perte.  \n",
    "Nous obtenons en ce point pour un param√®tre $\\theta$ dont la valeur minise notre fonction de perte. \n",
    "\n",
    "\n",
    "<u>Graphique N¬∞2 :Descente de gradient, learning rate trop faible</u>\n",
    "<img src=\"https://raw.githubusercontent.com/Roulitoo/cours_iae/master/00_intro/img/descente_gradient_2.png?token=GHSAT0AAAAAABZOBGATYCCCAVANYEDMAHTCY3CYY6Q\" alt=\"fig_2_intuition_svm.png\" style=\"width:600px;\"/>\n",
    "\n",
    "Il est important que la taille de 'saut' de mise √† jour de la valeur de votre param√®tre $\\theta$ ne soit pas trop faible.\n",
    "On appelera le param√®tre qui contr√¥le le 'saut' **LEARNING RATE**.  \n",
    "Si celui-ci est trop faible vos 'sauts' seront petits il faudra beaucoup d'it√©rations avant de trouver le param√®tre optimal.\n",
    "\n",
    "\n",
    "<u>Graphique N¬∞3 :Descente de gradient, learning rate trop haut</u>\n",
    "<img src=\"https://raw.githubusercontent.com/Roulitoo/cours_iae/master/00_intro/img/descente_gradient_3.png?token=GHSAT0AAAAAABZOBGASJVGZSIW23ZBCCRT6Y3CY5OA\" alt=\"fig_2_intuition_svm.png\" style=\"width:600px;\"/>\n",
    "\n",
    "A l'inverse si le *LEARNING RATE* est trop √©lev√© vous pourriez ne jamais trouver l'optimal de votre fonction.  \n",
    "Le calcul divergera et ne trouvera jamais de minimun local."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un peu de math pour comprendre comment la descente de gradient marche.\n",
    "C'est un concept fondamental pour les algorithmes de machine learning!!\n",
    "\n",
    "Exemple descente de gradient avec fonction de co√ªt MSE pour un mod√®le lin√©aire:\n",
    "\n",
    "On d√©finit un fonction lin√©aire avec un vecteur de param√®tre $\\theta$  \n",
    "$\\widehat{y} = \\theta_0 + \\theta_1x1+...+\\theta_nxn$\n",
    "\n",
    "o√π  :\n",
    "\n",
    "- $\\theta_0 : Biais\\space du\\space modele $\n",
    "- $\\theta_n : Param√®tre \\space du \\space mod√®le$\n",
    "- $\\widehat{y} : Valeure\\space pr√©dite$\n",
    "- $ n : Nombre \\space de \\space features$\n",
    "\n",
    "\n",
    "En forme vectorielle ca donne l'√©quation suivante\n",
    "\n",
    "$ \\widehat{y} = h_\\theta(x) = \\theta.X$\n",
    "\n",
    "On d√©finit la fonction de perte de ce mod√®le comme :\n",
    "\n",
    "$MSE(X, h_\\theta) = \\frac{1}{N}\\sum_{i=1}^N (y_i-\\widehat{y_i})¬≤$\n",
    "\n",
    "Pour impl√©menter la descente de gradient, vous devez calculer le gradient de la fonction de co√ªt MSE en fonction de ses param√®tres $\\theta$\n",
    "On doit donc calculer toutes les d√©riv√©es partielles de la fonction MSE\n",
    "\n",
    "$\\frac{\\partial}{\\partial \\theta_j} MSE(\\theta) = \\frac{2}{N}\\sum_{i=1}^N (\\theta^Tx^{(i)}-y^{(i)})x^{(i)}_j$\n",
    "  \n",
    "ou au format vectoriel\n",
    "\n",
    "$\\nabla_\\theta MSE(\\theta) = \\begin{pmatrix}  \\frac{\\partial}{\\partial \\theta_0} \\\\ \\frac{\\partial}{\\partial \\theta_1} \\\\ . \\\\\\frac{\\partial}{\\partial \\theta_n}  \\end{pmatrix} =\\frac{2}{N}X^T (X\\theta-y)$  \n",
    "\n",
    "Une fois que vous avez le vecteur de descente de gradient, vous devez simplement mettre √† jour vos param√®tre $\\theta$ jusqu'√† atteindre le minimun de votre fonction.\n",
    "\n",
    "$\\theta^{(next)} = \\theta - \\eta\\nabla_\\theta MSE(\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemple Descente de gradient\n",
    "Un exemple en dimension 1 pour mieux comprendre üòÄ\n",
    "\n",
    "Nous avons une fonction  $f(x) = 3x^2 -2x +5 $ et nous souhaitons minimiser cette fonction\n",
    "\n",
    "<u>Graphique N¬∞4 :Exemple descente de gradient</u>\n",
    "<img src=\"https://raw.githubusercontent.com/Roulitoo/cours_iae/master/00_intro/img/exemple_grad_1D_4.png?token=GHSAT0AAAAAABZOBGATOM24LDELJ53HLCDQY3C4SIQ\" alt=\"fig_2_intuition_svm.png\" style=\"width:500px;\"/>\n",
    "\n",
    "Etape 1 : On calcule son vecteur gradient \n",
    "\n",
    "En dimension le vecteur est de taille 1, donc on calcul uniquement une d√©riv√©e\n",
    "\n",
    "$f'(x) = 6x -2x $\n",
    " \n",
    "Etape 2 : On initialise une valeur de $x$ par d√©faut et une valeur pour le learning rate\n",
    "\n",
    "On pose $x_0 = 5$ et $\\eta = 0.05$\n",
    "\n",
    "La formule pour les √©tapes de descente de gradient en D1 est donc :\n",
    "$x_{n+1} = x_n -\\eta*f'(x_n)$\n",
    "\n",
    "Etape 3 : It√©ration sucessive d√©scente de gradient\n",
    "\n",
    "<u>Graphique N¬∞5 :Exemple descente de gradient</u>\n",
    "<img src=\"https://raw.githubusercontent.com/Roulitoo/cours_iae/master/00_intro/img/descente_grad_exemple_5.png?token=GHSAT0AAAAAABZOBGATDNVWXSKSYDGE55KQY3C5XZA\" alt=\"fig_2_intuition_svm.png\" style=\"width:500px;\"/>\n",
    "\n",
    "\n",
    "Successivement la valeur de $\\theta$ se rapproche de la valeur de $x=\\frac{1}{3}$ qui minise la fonction.\n",
    "Quand vous utiliserez l'hyperparam√®tre **learning rate** pour un algo de machine learning c'est exactement ca qui se passera en back.\n",
    "\n",
    "> Vous savez maintenant ce qu'est la descente de gradient, bravo !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOSS function or Metric function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les 2 termes sont souvents confondus dans le domaine du machine learning mais il repr√©sente pourtant 2 concepts bien diff√©rent.\n",
    "\n",
    "#### Loss function\n",
    "La *loss function* ou *cost function* est utilis√©e pour entrainer notre mod√®le de ML et c'est la fonction que nous allons chercher √† optimiser (minimiser ou maximiser) les param√®tres du mod√®les.  \n",
    "\n",
    "Globalement elle donne l'√©cart entre la qualit√© de notre pr√©diction et la valeur de r√©f√©rence.\n",
    "\n",
    "Exemple : \n",
    "\n",
    "- Logistic sigmoid\n",
    "- Mean squared error\n",
    "- Cross-Entropy\n",
    "- Hinge loss\n",
    "- etc\n",
    "\n",
    "\n",
    "\n",
    "#### Metric function\n",
    "\n",
    "La *Metric function* est quant √† lui un crit√®re √† post√©riori qui permet d'√©valuer la qualit√©/performance du mod√®le. C'est un quantifieur permettant au cr√©ateur du mod√®le d'√©valuer si son mod√®le est bon ou mauvais.\n",
    "\n",
    "Exemple : \n",
    "\n",
    "- Accuracy\n",
    "- F1 Score\n",
    "- Recall\n",
    "- etc\n",
    "\n",
    "\n",
    "#### Spoiler\n",
    "\n",
    "Certaines $Loss function$ sont aussi des $Metric function$, c'est quasi tout le temps le cas pour les mod√®les de r√©gression!\n",
    "\n",
    ">Toutes les loss function de scikit : https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperpam√®tre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il ne faut pas confondre les param√®tres d'un mod√®le qui d√©pendent directement des donn√©es et sont calcul√©es analytiquement avec les hyperparam√®tres.\n",
    "\n",
    "Tous les mod√®les de machine learning n'en poss√®dent pas. Par exemple la r√©gression lin√©aire ne poss√®de aucun hyperparam√®tre, l'ensemble de ses param√®tres est calcul√© √† partir des donn√©es.\n",
    "\n",
    "En revanche les mod√®les de machine learning complexe en poss√®de √©normement. Ils permettent de contr√¥ler l'aprrentissage du mod√®le et impacte donc directemnt les param√®tres du mod√®les.\n",
    "Leur valeur n'est pas connu √† l'avance et la seule fa√ßon de trouver la combinaison optimale est de faire varier leur valeur tout en observant l'impact sur la fonction de perte.\n",
    "\n",
    "\n",
    "Exemple :\n",
    "\n",
    "- Le learning rate \n",
    "- Regularization parameter (ridge, lasso,...)\n",
    "- Max depth, Max features ( random forest, ...)\n",
    "\n",
    ">Pour approndir\n",
    ">https://towardsdatascience.com/parameters-and-hyperparameters-aa609601a9ac\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search\n",
    "\n",
    "Le moyen le plus simple de trouver les valeurs de vos hyperparam√®tres qui maximise ou minimise ou votre *loss function* est de r√©aliser un *grid search*.\n",
    "\n",
    "C‚Äôest une m√©thode d‚Äôoptimisation (hyperparameter optimization) qui va nous permettre de tester une s√©rie de param√®tres et de comparer les performances pour en d√©duire le meilleur param√©trage.\n",
    "On d√©finit une plage de valeur possible pour nos hyperparam√®tres et toutes les combinaisons seront test√©es pour voir lesquelles donnent le meilleur mod√®le.\n",
    "\n",
    "\n",
    "![test](https://1.bp.blogspot.com/-lnKhRVwqOZ8/XxXBC5rSkHI/AAAAAAAABL0/CXiYFK3JSFE9lBR0UYiKivmBBGYFVeM6wCLcBGAsYHQ/s1632/Picture1.jpg)\n",
    "Il existe 3 types de grid search utilis√©e :\n",
    "\n",
    "- **Grid search** : On d√©finit manuellement les combinaisons des hyperparam√®tres. Plus vous aurez de l'exp√©rience plus il sera facile de d√©finir les hyperparamtres et donc r√©duire le champ des possibilit√©s.\n",
    "\n",
    "\n",
    "- **Random Grid search** : On va sp√©cifier l'espace dans le quel les hyperparam√®tres prennent leur valeur et on va laisser la comparaison se faire.\n",
    "\n",
    "On peut voir graphiquement le r√©sultat des 2 approches.\n",
    "\n",
    "Le random search donne g√©n√©ralement de meilleur performance mais il est aussi beaucoup plus couteux en temps de calcul... A vous d'arbitrer.\n",
    "\n",
    "- **Bayesian Grid search** :  Cette m√©thode diff√©re des autres car elle va s√©lectionner les hyperparam√®tres √† chaque entrainement de mod√®le conditionnelement aux r√©sultats du pr√©c√©dent. Th√©oriquement la combinaison de meilleur param√®tre sera trouv√© plus vite que pour les 2 pr√©c√©dents et elle retira automatiquement les espaces o√π la combinaison d'hyperparam√®tre est mauvaise.\n",
    "\n",
    "\n",
    "\n",
    "Pour impl√©menter ces m√©thodes en python, vous pouvez utiliser les codes suivants :\n",
    "\n",
    "```python\n",
    "#Import function\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Define grid\n",
    "param_grid = {\n",
    "    \"max_samples\": [0.2, 0.3, 0.4, 0.4, 0.1],\n",
    "    \"max_features\": [1, 2],\n",
    "    \"max_depth\": [ 4, 20,] \n",
    "            }\n",
    "#Grid\n",
    "reg_grid = GridSearchCV(RandomForestClassifier(),\n",
    "                        param_grid=param_grid,\n",
    "                        cv=5,\n",
    "                        n_jobs=4, \n",
    "                        scoring='accuracy'\n",
    "                       )\n",
    "\n",
    "#Fit model\n",
    "model_grid = reg_grid.fit(X, y)\n",
    "#get best estimator\n",
    "model_grid.best_estimator_\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "#### Random search\n",
    "\n",
    "```python \n",
    "#Import function\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "#Define grid\n",
    "param_grid = {\n",
    "    \"max_samples\": uniform(1e-2, 0.5),\n",
    "    \"max_features\": randint(1,2),\n",
    "    \"max_depth\": randint(4, 400) \n",
    "}\n",
    "\n",
    "# Random\n",
    "reg_rand = RandomizedSearchCV(RandomForestClassifier(),\n",
    "                         param_distributions=param_grid,\n",
    "                         cv=5,\n",
    "                         n_jobs=4,\n",
    "                         scoring='accuracy',\n",
    "                         random_state=42)\n",
    "#Fit model\n",
    "model_rand = reg_rand.fit(X, y)\n",
    "\n",
    "#Print best estimator\n",
    "print(model_rand.best_estimator_)\n",
    "\n",
    "```\n",
    "#### Bayesian search\n",
    "\n",
    "```python \n",
    "#! pip install scikit-optimize\n",
    "from skopt import BayesSearchCV\n",
    "# parameter ranges are specified by one of below\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "#Real : Nombre r√©el\n",
    "#Categorial : data cat√©goriel, exemple 'bleu', 'rouge'\n",
    "#Integer : ...\n",
    "\n",
    "#Define grid\n",
    "param_grid = {\n",
    "    \"max_samples\": Real(1e-2, 0.5),\n",
    "    \"max_features\": Integer(1,2),\n",
    "    \"max_depth\": Integer(4, 400) \n",
    "}\n",
    "#grid\n",
    "reg_bay = BayesSearchCV(estimator=RandomForestClassifier(),\n",
    "                    search_spaces=param_grid,\n",
    "                    cv=5,\n",
    "                    n_jobs=8,\n",
    "                    scoring='accuracy',\n",
    "                    random_state=42)\n",
    "#Fit the data\n",
    "model_bay = reg_bay.fit(X, y)\n",
    "#Meilleur estimateur\n",
    "print(model_bay.best_estimator_)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "> Article int√©ressant sur le grid search et random search  \n",
    ">https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/  \n",
    "> Comparaison 3 types de grid search, article  \n",
    ">https://towardsdatascience.com/bayesian-optimization-for-hyperparameter-tuning-how-and-why-655b0ee0b399  \n",
    "> Doc impl√©mentation bayesian grid search  \n",
    ">https://scikit-optimize.github.io/stable/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computational complexity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En machine learning, le $computational complexity$ ou complexit√© de l'algorithm est le montant de ressources n√©cessaire pour utiliser un mod√®le.\n",
    "On distingue le temps d'entrainement d'un mod√®le et le temps de pr√©diction d'un mod√®le d√©ja entrain√©.\n",
    "\n",
    "A titre d'exemple.\n",
    "\n",
    "La r√©gression lin√©aire impl√©ment√©e avec sklearn poss√®de une compl√©xit√© de $O(n_{samples} n^2_{features})$.\n",
    "Si on double le nombre de ligne et de colonnes du data set on augmente alors de $2.2^2 = 8$  le temps de calcul. Un temps de calcul alors 8 fois plus long.\n",
    "\n",
    "En revanche la pr√©diction ne d√©pend que du nombre de colonnes $O(n_{features})$\n",
    "\n",
    "> Tableau comparaison model complexity :https://www.thekerneltrip.com/machine/learning/computational-complexity-learning-algorithms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "liste √† voir avec eux\n",
    "\n",
    "Gradient Descent  XX\n",
    "Learning rate  XX\n",
    "Hyperparameter  XX\n",
    "Loss function  XX\n",
    "Computational complexity  \n",
    "Grid search  XX\n",
    "Scaling features  X\n",
    "Evaluation metrics XX \n",
    "Imbalanced dataset X\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
