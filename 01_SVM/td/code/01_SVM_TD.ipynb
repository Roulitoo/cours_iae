{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> TD N¬∞1 : SVM avec sklearn <center><h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "#sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Classifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier , LogisticRegression\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "#Regressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svc_decision_boundary(svm_clf, xmin, xmax):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    SEULEMENT pour la fonction SVC de skealearn, pas de LinearSVC\n",
    "    \n",
    "    Function qui permet de recup√©rer la constante et le coefficient directeur\n",
    "    d'un svm apr√®s entraintement.\n",
    "    \n",
    "    Un svm lineaire est de la forme w0*w0+w1*x1 +b =0\n",
    "    donc \n",
    "    >= x1= -w0/w1 *x0 -b/w1\n",
    "    \n",
    "    avoir x1 en fonction de x0 permet de tracer la zone de d√©cision du SVM \n",
    "    et ainsi avoir une r√©pr√©sentation graphique\n",
    "    \n",
    "    Pour calculer les marges on rajoute +- 1/w[1]\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    w = svm_clf.coef_[0]\n",
    "    b = svm_clf.intercept_[0]\n",
    "\n",
    "    # At the decision boundary, w0*x0 + w1*x1 + b = 0\n",
    "    # => x1 = -w0/w1 * x0 - b/w1\n",
    "    x0 = np.linspace(xmin, xmax, 200)\n",
    "    decision_boundary = -w[0]/w[1] * x0 - b/w[1]\n",
    "\n",
    "    margin = 1/w[1]\n",
    "    gutter_up = decision_boundary + margin\n",
    "    gutter_down = decision_boundary - margin\n",
    "\n",
    "    svs = svm_clf.support_vectors_\n",
    "    plt.scatter(svs[:, 0], svs[:, 1], s=180, facecolors='#FFAAAA')\n",
    "    plt.plot(x0, decision_boundary, \"k-\", linewidth=2)\n",
    "    plt.plot(x0, gutter_up, \"k--\", linewidth=2)\n",
    "    plt.plot(x0, gutter_down, \"k--\", linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_f_importances(coef_svm , names):\n",
    "    ''' \n",
    "    Cette fonction permet de visualiser l'importance de chaque variable pour le mod√®le SVM\n",
    "    Vous devez passer 2 arguments :\n",
    "    \n",
    "    - coef_svm : Les co√©fficients du mod√®le disponible apr√®s votre .fit()\n",
    "      On le r√©cup√®re avec la commande suite  svc_fit.coef_[0]\n",
    "      \n",
    "    - names : est le nom des features que vous avez utilis√©e.\n",
    "      ATTENTION √† passer dans le m√™me ordre que pour l'entrainement du mod√®le\n",
    "    \n",
    "    '''\n",
    "    imp = coef_svm\n",
    "    imp,names = zip(*sorted(zip(imp,names)))\n",
    "    plt.barh(range(len(names)), imp, align='center')\n",
    "    plt.yticks(range(len(names)), names)\n",
    "    plt.show()\n",
    "\n",
    "#features_names = ['input1', 'input2']\n",
    "#svm = svm.SVC(kernel='linear')\n",
    "#svm.fit(X, Y)\n",
    "#f_importances(svm.coef_[0], features_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice N¬∞1 : Classification donn√©es IRIS avec un SVM\n",
    "\n",
    "\n",
    "#### Exploration and data analysis (EDA)\n",
    "1) Importer le dataset Iris\n",
    "\n",
    "2) Faire des stats descriptives pour mieux comprendre le dataset\n",
    "\n",
    "3) Recoder les donn√©es dans le bon format si n√©cessaire \n",
    "\n",
    "4) D√©couper le dataset en train et test\n",
    "\n",
    "#### Mod√©lisation binaire\n",
    "\n",
    "5) Importer les mod√®les de  r√©gression logistic , SVC, LinearSVC et SGDClassifier avec sklearn\n",
    "\n",
    "6) Supprimer une des target du data Iris et cr√©er un nouveau dataset qui ne contient que 2 esp√®ces.\n",
    "\n",
    "7) Choisir maximum 2 colonnes dans votre nouveau data et entrainer un SVM avec le module SVC.<br>\n",
    "7.1) Tracer la fronti√®re de d√©cision de votre mod√®le avec la fonction fournie. Visualiser le r√©sultat.<br>\n",
    "7.2) Faites varier le crit√®re de r√©gularisation $C$ et regarder son impact sur la fronti√®re de d√©cision. Tester plusieurs valeurs.<br>\n",
    "7.3) Commenter l'effet de C sur votre mod√®le<br>\n",
    "7.4) Recommencer avec une autre paire de features pour fit votre mod√®le.<br>\n",
    "\n",
    "\n",
    "8) Entrainer les 4 mod√®les sur les donn√©es et √©valuer la performance des mod√®les (uniquement avec le dataset train)\n",
    "   Utiliser les valeurs par d√©faut des mod√®les, ne pas tuner.<br>\n",
    "   R√©aliser une cross-validation pour √©valuer votre mod√®le.<br>\n",
    "   Justifier le type de cross_validation choisie.<br>\n",
    "\n",
    "9) Imaginons que ce soit le SVM par d√©faut qui donne le meilleur score, tuner ce mod√®le pour l'am√©liorer\n",
    "\n",
    "9.1) Utiliser un grid search pour d√©finir les meilleurs hyperparam√®tres.<br>\n",
    "9.2) Utiliser une learning curve pour voir comment votre mod√®le apprend √† partir des donn√©es.<br>\n",
    "9.3) **Uniquement si vous avez le temps**, examiner l'influence des hyperparam√®tres sur la qualit√© de votr√© mod√®le avec des          *validation curve*.\n",
    "\n",
    "9) Entrainer votre mod√®le sur les meilleurs hyperparam√®tres. \n",
    "\n",
    "10) R√©aliser une pr√©diction avec votre mod√®le sur le dataset test.<br> \n",
    "    Evaluer la performance de votre mod√®le.<br>\n",
    "    Regarder les variables qui participent le plus √† votre mod√®le, utiliser la fonction fournie.<br>\n",
    "    Commenter les r√©sultats\n",
    "\n",
    "\n",
    "#### Mod√©lisation multiclass\n",
    "\n",
    "11) A partir du dataset iris avec les 3 esp√®ces, r√©aliser une classification multiclass\n",
    "    Tester les diff√©rentes m√©thodes, OVR et OVO\n",
    "    Tuner votre mod√®le pour obtenir la meilleur performance possible.\n",
    "    Commenter. Existe-il des diff√©rences entre les m√©thodes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie code, a vous de jouer üêç"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration and data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Importer le dataset Iris depuis sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "#Import dataset from sklearn\n",
    "\n",
    "<df_name> = datasets.load_iris()\n",
    "\n",
    "#Si besoin\n",
    "#pd.DataFrame(data= np.c_[<df_name>.data, <df_name>.target], columns=<df_name>['feature_names']+['species'] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Statistiques descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.describe() d'un pandas dataframe peut aider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Recoder variable si besoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mod√©lisation binaire\n",
    "\n",
    "Attention √† bien choisir un dataset contenant uniquement **2** esp√®ces pour la mod√©lisation"
   ]
  },
    {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) D√©couper data set en train et test"
   ]
  },
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Importer les modules pour la mod√©lisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) Supprimer une esp√®ce de fleur du dataset iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7) Garder uniquement 2 colonnes du dataset et entrainer un SVM avec module SVC\n",
    "\n",
    "7.1) Tracer la fronti√®re de d√©cision de votre mod√®le avec la fonction **plot_svc_decision_boundary**. Visualiser le r√©sultat.<br>\n",
    "7.2) Faites varier le crit√®re de r√©gularisation $C$ et regarder son impact sur la fronti√®re de d√©cision. Tester plusieurs valeurs.<br>\n",
    "7.3) Commenter l'effet de $C$ sur votre mod√®le<br>\n",
    "7.4) Recommencer avec une autre paire de features pour fit votre mod√®le.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model SVC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tracer d'abord les donn√©es d'entrainement avant d'utiliser la fonction ci-dessous\n",
    "#Regarder les commentaires de la fonction pour mieux comprendre, au d√©but du notebook\n",
    "\n",
    "\n",
    "#plot_svc_decision_boundary(svm_clf, xmin, xmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8) Entrainer les 4 mod√®les sur votre dataset d'entrainement\n",
    "\n",
    "- LogisticRegression\n",
    "- LinearSVC\n",
    "- SVC\n",
    "- SGDClassifier\n",
    "\n",
    "Conseils :\n",
    "- Utiliser les valeurs par d√©faut des mod√®les, ne pas tuner.<br>\n",
    "- R√©aliser une cross-validation pour √©valuer votre mod√®le.<br>\n",
    "- Justifier le type de cross_validation choisie.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On continue de travailler sur le dataset iris mais vous allez charger une version l√©g√©rement modifi√©e.\n",
    "#Elle est disponible directement sur github dans\n",
    "# cours_iae/01_SVM/td/data/\n",
    "\n",
    "<df_name> = pd.read_csv('.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9)  Tuner le mod√®le SVM pour am√©liorer ses performances\n",
    "\n",
    "A vous de choirsir entre **SGDClassifier** ou **SVC** ou **LinearSVC** mais justifier pourquoi l'un ou l'autre.\n",
    "\n",
    "9.1) Utiliser un grid search pour d√©finir les meilleurs hyperparam√®tres.<br>\n",
    "9.2) Utiliser une learning curve pour voir comment votre mod√®le apprend √† partir des donn√©es.<br>\n",
    "9.3) Uniquement si vous avez le temps, examiner l'influence des hyperparam√®tres sur la qualit√© de votr√© mod√®le avec des validation curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10) Entrainer votre mod√®le sur les hyperparam√®tres qui donne la meilleur performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11) R√©aliser une pr√©diction avec votre mod√®le sur le dataset test. \n",
    "\n",
    "- Evaluer la performance de votre mod√®le \n",
    "- Regarder les variables qui participent le plus √† votre mod√®le, utiliser la fonction fournie \n",
    "- Commenter les r√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nom de vos features \n",
    "features_names = ['input1', 'input2','inputN']\n",
    "#Votre meilleur mod√®le\n",
    "\n",
    "#svm = svm.SVC(kernel='linear')\n",
    "#svm.fit(X, Y)\n",
    "\n",
    "#Plot l'importance des features pour le mod√®le en fonction de ses co√©fficients\n",
    "svm_f_importances(svm.coef_[0], features_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice N¬∞2 : Mod√©lisation multiclass avec dataset IRIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Importer le dataset Iris depuis sklearn\n",
    "\n",
    "Avec le module datasets.load_iris(). A ce stade plus besoin d'utiliser mon dataset Iris modifi√©.\n",
    "\n",
    "Ne supprimer pas la 3√®me esp√®ce de fleur, nous allons maintenant utiliser les 3 target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Entrainer un SVM pour une classification multiclass\n",
    "\n",
    "- D√©finir la strat√©gie en s'appuyant sur les √©l√©ments vus en cours\n",
    "- Que faut-il modifier pour que le SVM puisse faire une classification multiclass?\n",
    "\n",
    "- Combien de mod√®le faut-il pr√©dire?\n",
    "- Tester avec la m√©thode OVO et OVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OneVsRestClassifier\n",
    "#OneVsOneClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Existe-t-il des diff√©rences entre OVO et OVR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3> Merci de rendre lisible votre code, un groupe pr√©sentera ses travaux √† l'oral √† la fin du cours.</h3></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
