<center><h1> Artificial Neural Network sous Python</h1></center>
<p align="center">
<img src="https://github.com/Roulitoo/cours_iae/blob/master/00_intro/img/Logo_IAE_horizontal.png" alt="Logo IAE.png" style="width:200px;"/>
</p>

#### Table of Contents
[1. Histoire des r√©seaux de neurones](#1-histoire-des-r%C3%A9seaux-de-neurones)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[1.1 Neurone biologique & neurone artificiel ](#11-du-neurone-biologique-au-neurone-artificiel)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[1.2 logique computationelle ](#12-logique-de-computation-dun-neurone)<br>

[2. Le perceptron](#2-le-perceptron)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[2.1 Fonction d'activation](#21-fonction-dactivation)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[2.2 D√©finition d'un perceptron](#22-d%C3%A9finition-perceptron)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[2.3 Entrainement perceptron](#23-entrainement-perceptrone)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[2.4 Classification non lin√©aire](#24-probl%C3%A8me-pour-la-classification-lin%C3%A9aire)<br>

[3. Perceptron multicouche & backpropagation](#3-perceptron-multicouche-et-backpropagation)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[3.1 Algorithm r√©tropropagation](#31-algorithme-de-r%C3%A9tropropagation-du-gradient)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[3.2 Fonctions d'activations](#32-fonctions-dactivations-communes)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[3.3 MLP pour la r√©gression](#33-mlp-pour-la-r%C3%A9gression)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[3.4 MLP classification](#34-mlp-pour-la-classification
)<br>

[4. Tensorflow & Keras](#4-mpl-avec-keras-et-tensorflow)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[4.1 Tensorflow](#41-tensorflow)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[4.2 Keras](#42-keras)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[4.3 Comment utiliser Keras](#43-comment-utiliser-keras)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[4.4 Classification avec Keras](#44-classification-avec-keras)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[4.4.1 Impl√©mentation avec Keras](#441-impl%C3%A9mentation-avec-keras)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[4.4.2 Compiler le mod√®le](#442-compiler-le-mod%C3%A8le)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[4.4.3 Entrainer et √©valuer](#443-entrainer-et-%C3%A9valuer-le-mod%C3%A8le)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[4.4.4 Learning curve avec Keras](#444-leaning-curve-keras)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[4.5 R√©gression avec Keras](#45-r%C3%A9gression-avec-keras)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[4.5.1 Wide and Deep Neural](#451-wide-and-deep-neural-model)<br>
[5.Hyperparam√®tre tuning](#5-hyperparameter-tuning)<br>


## 1-Histoire des r√©seaux de neurones

Historiquement les r√©seaux de neurones se sont inspir√©s du fonctionnement des neurones biologique humain.<br>
Leur conception provient d'une repr√©sentation sch√©matique de comment marche notre traitement de l'information.<br>

Les r√©seaux de neurones sont donc un mod√®le de machine learning inspir√© par le fonctionnement des neurones.<br>

> D'apres [Yann Lecun](https://fr.wikipedia.org/wiki/Yann_Le_Cun), ' Les r√©seaux de neurones ne pr√©tendent pas plus d'√©crire le cerveau qu'une aile d'avion copie celle d'un oiseau'

Aujourd'hui ces mod√®les se sont largement diffus√©s et sont utilis√©s pour des probl√©matiques li√©es au traitement cognitif humain.<br> 
La majorit√© de leur domaine d'application a pour but de remplacer des actions humaines.

**Exemple :**

- Reconnaissance vocale avec Siri, Apple
- Syst√®me de recommandation, Netflix
- Voiture autonome, Tesla
- Jouer aux √©checs, Google Deep Mind
- ...


Les premi√®res recherches sur ce type de mod√®le **datent des ann√©es 1950** et ont √©t√© r√©alis√©es par 2 neurologues, **Warren McCulloch** et **Walter Pitts**.<br>
Leurs travaux consistaient √† d√©crire comment fonctionnaient les neuronnes en utilisant les math√©matiques afin de d√©crire des neurones dits formels.

Apr√®s ces premi√®res recherches, le domaine a connu une longue p√©riode sans r√©elle avanc√©e. De nombreux freins emp√©chaient leur utilisation et des mod√®les de machine learning traditionnels leur √©tait pr√©r√©f√©r√© (type SVM).

Cependant √† la fin des ann√©es 90 de nombreuses avanc√©es ont permis la d√©mocratisation des r√©seaux de neurones (Artificial Neural Network)

- La quantit√© de Data disponible. G√©n√©ralement les ANN offrent de meilleure performance sur les jeux de donn√©es tr√®s grand
- L'augmentation de la puissance de calcul et l'apparition des GPU facilitant le traitement distribu√©
- L'am√©lioration de l'algorithme d'apprentissage (descente de gradient)


### 1.1-Du neurone biologique au neurone artificiel

On peut observer sur l'image N¬∞1 une cellule neurale obtenue dans le cerveau d'un animal.

Graphique N¬∞1 : Cellule neurale d'un animal

<img src="https://github.com/Roulitoo/cours_iae/blob/master/02_ANN/img/neural_bio_01.png" alt="01_image_neurone.png" style="width:600px;"/>

La cellule est compos√©e d'un noyau et un long axon permettant de transmettre l'information avec un faible courant √©lectrique √† une synapse qui ensuite, lib√®re une substance chimique appel√©e neurotransmetteur et qui √† son tour sera re√ßu par un neurone et ce nouveau neurone transmettra une information via une impulsion √©lectrique.

Les neurones sont tous interconnect√©s entre eux et on d√©nombre en moyenne **86 milliards de neurones pour l'esp√®ce humaine**.<br>
Sur l'image N¬∞2 on peut observer un plan en coupe repr√©sentant l'interconnexion des neurones entre eux.

Graphique N¬∞2 : Connexion entre neurones

<img src="https://github.com/Roulitoo/cours_iae/blob/master/02_ANN/img/multi_neural_bio_02.png" alt="02_image_connect_neural.png" style="width:600px;"/>

Garder √† l'esprit la structure de cette image qui repr√©sente des neurones lin√©airement maill√©s.

### 1.2-Logique de computation d'un neurone

Logique de computation des neurones, travaux de 1950. Traduction d'un neurone biologique dans l'espace math√©matique

Graphique N¬∞3: Logique formelle des neurones

<img src="https://github.com/Roulitoo/cours_iae/blob/master/02_ANN/img/neural_formal_03.png" alt="03_logic_neural.png" style="width:800px;"/>

On d√©nombre **4 cas formul√©s par Warren McCulloch et Walter Pitts en 1943.**

- Le premier r√©seau s'active si le neurone A est activ√© puis C s'active car il re√ßoit l'input de A
- Le second cas s'active si le neurone A et le neurone B s'active puis envoie leur input √† C. A seul ou B seul ne suffit pas pour activer C
- Le troisi√®me cas s'active si A ou B est activ√© ou les deux.
- Le quatri√®me s'active si seulement A est activ√© et B est off.

Si on combine ces 4 formes de logique math√©matique nous pouvons d√©ja cr√©er beaucoup de mod√®les de r√©seaux de neurones.<br> C'est d'ailleurs ce que nous allons voir par la suite.


## 2-Le perceptron

Le perceptron est le mod√®le de r√©seaux de neurones le plus simple. Il a √©t√© invent√© en 1957 par Frank Rosenblatt.<br>
Il est bas√© sur un type de neurone l√©g√®rement diff√©rent de ceux du graphique N¬∞3.<br>
On le nomme **threshold logic unit(TLU)**

Les intput et output sont ici des nombres et non pas des valeurs binaires (on, off)
Chaque input est associ√© √† un poids (w)

Le TLU not√© z est √©gal √† 

Equation N¬∞1 : Fonction li√©naire<br>

$z=w_1x_1+w_2x_2+...+w_nx_n = X^TW$ <br>

Puis on applique √† z la *step function* qui g√©n√®re l'output.<br>

On note $h_w(x) = step(z)$ la *step function*

Graphique N¬∞4 : Architecture d'un perceptron

<img src="https://github.com/Roulitoo/cours_iae/blob/master/02_ANN/img/percetron_04.png" alt="04_perceptron_archi.png" style="width:600px;"/>


### 2.1-Fonction d'activation

La fonction d'√©tape la plus utilis√©e pour le perceptron est la *Heaviside step function* de formule:<br>

Equation N¬∞2 : Heaviside<br>

$$\normalsize heaviside(z)=\begin{cases}0&if(z\lt 0)\\\1&if(z\geq 0)\end{cases}$$

On peut √©galement utiliser la fonction signe d√©finie comme suit :<br>

Equation N¬∞3 : Fonction sign <br>

$$\normalsize sgn(z)=\begin{cases}-1&if(z\lt 0)\\\0&if(z= 0)\\\\+1&if(z>0)\end{cases}$$

Ce type d'architecture peut √™tre utlis√©e pour des classifications lin√©aires simples.<br>
Le mod√®le ressemble √©norm√©ment √† une r√©gression logistique ou un SVM. La seule diff√©rence est qu'il g√©n√®re syst√©matiquement en output la classe √† pr√©dire et non pas une proba comme une r√©gression logistique.

Note:

> On parle d'un r√©seau de neurones pleinement connect√© si tous ses neurones sont reli√©s (fully connected layer)

> Le perceptron peut √©galement servir pour du multiclass

Suivant le nombre de neurones dans la couche de sortie nous pouvons nous ramener √† une probl√©matique de multiclassification 

Graphique N¬∞5 : Perceptron architecture pour multiclass 

<img src="https://github.com/Roulitoo/cours_iae/blob/master/02_ANN/img/perceptron_05.png" alt="05_perceptron_multi.png" style="width:600px;"/>

### 2.2-D√©finition perceptron

Math√©matiquement, sa fonction est de la forme :

Equation N¬∞4 : Fonction d'un perceptron *fully connected layer*<br>

$\normalsize h_{W,b} = \phi(XW+b)$

o√π

- $X$ : Matrice de nos inputs<br>
- $W$ :  Matrice des poids attribu√©s √† chaque lien entre neurones. Sauf pour le neurone biais.         
  Elle est de taille nombre de neurones dans l'input layer et nombre de colonnes par neurone artificiel<br>
- $b$ : Est le vecteur qui contient tous les poids entre le biais et les neurones artificiels<br>
- $\phi$ : Est la fonction d'activation. C'est un TLU quand la fonction d'activation est de type **step function**

### 2.3-Entrainement perceptron


Le premier mod√®le du perceptron d√©velopp√© en 1957 par **Frank Rosenblatt** s'inspire largement de la r√®gle de *Hebb*(1949) pour l'apprentissage de son mod√®le.<br>

La r√®gle de *Hebb* s'appuie sur une √©tude biologique de nos neurones et √† d√©terminer que quand un neurone en d√©clenche un autre leur lien se renforce.<br>

C'est exactement sur ce principe que Frank Rosenblatt d√©veloppe sa r√®gle d'apprentissage pour son perceptron.
Le perceptron renforce **le lien entre ses neurones qui aides √† r√©duire l'erreur de pr√©diction**, formellement cela se d√©finit comme suit:

Equation N¬∞6: R√®gle d'apprentissage du perceptron

$\normalsize w_{i,j} = w_{i,j}+ \eta(y_j-\hat{y_j})x_i $

o√π

- $w_{i,j}$ : Le poids de connexion entre le i√®me neurone et le j√®me output neuron 
- $x_i$ : La i_√®me valeur de l'√©chantillon  pass√© par un neurone
- $\hat{y_j}$ : L'output de du j√®me neurone de sortie
- $y_i$ : La target du j√®me output neuron pour une i√®me valeur de l'√©chantillon
- $\eta$ : Learning rate

‚ö†Ô∏è <br>
Le **perceptron** comme la r√©gression logistique est un **classifieur lin√©aire**.<br>
Il est incapable de produire une fronti√®re de d√©cision complexe!<br>
Cependant si la dataset est lin√©airement s√©parable il convergera vers une solution optimale.


L'impl√©mentation de cet algorithme est disponible sous sklearn avec le code suivant:

```python
#Package
import numpy as np
from sklearn.datasets import load_iris
from sklearn.linear_model import Perceptron
#Data
iris = load_iris()
X = iris.data[:, (2, 3)] # petal length, petal width
y = (iris.target == 0).astype(np.int) 
#Train model
per_clf = Perceptron()
per_clf.fit(X, y)
#Predict
y_pred = per_clf.predict([[2, 0.5]])
```

La fonction ressemble √©norm√©ment √† la fonction SGDClassifier (m√™mes hyperparam√®tres).<br> 
Vous pouvez donc acc√©der au perceptron via la fonction SGDClassifier en sp√©cifiant :
- la fonction de perteloss='perceptron'
- learning_rate="constant"
- eta0=1 (learning rate)
- penalty=None (no regularization).


```python
#Package
import numpy as np
from sklearn.datasets import load_iris
from sklearn.linear_model import SGDClassifier
#Data
iris = load_iris()
X = iris.data[:, (2, 3)] # petal length, petal width
y = (iris.target == 0).astype(np.int) 
#Train
clf = SGDClassifier(max_iter = 1000, loss='perceptron', eta0=1, learning_reate='constan', penalty=None)
clf.fit(X, Y)
#Predict
print(clf.predict([[2, 0.5]]))
```

üõà **En dehors des TD, pr√©f√©rez une r√©gression logistique qui retourne la probabilit√©  d'affectation √† une classe plut√¥t que le perceptron qui offre *hard threshold***

### 2.4-Probl√®me pour la classification lin√©aire

#### XOR probl√®me

En 1969, 2 auteurs,  Marvin Minsky and Seymour Papert,  ont r√©v√©l√© les nombreuses faiblesses du perceptron. Ce mod√®le est incapable de r√©aliser une classification non lin√©aire et les auteurs ont d√©montr√© qu'il ne pouvait r√©soudre un probl√®me trivial comme **XOR**

Les chercheurs ont trouv√© une parade astucieuse afin de continuer √† utiliser ce type de mod√®le pour des probl√®mes de classification non lin√©aire.<br>
En stackant des perceptrons, on peut √©liminer plusieurs limites du perceptron classique de Rosenblatt.

Sur le graphique N¬∞, on peut observer l'architecture du perceptron stack√© avec tous les poids √©gaux √† 1 sauf les 4 poids mis en rouge.

Graphique N¬∞6 : Perceptron pour probl√®me XOR

<img src="https://github.com/Roulitoo/cours_iae/blob/master/02_ANN/img/xor_problem_06.png" alt="06_XOR.png" style="width:600px;"/>

üõà On nomme ce type d'architecture MLP (multi layer perceptron).

## 3-Perceptron multicouche et backpropagation

Le multi layer perceptron est compos√© de : 
- Une couche d'entr√©e appel√©e *input layer* de taille $\large  n_{features}$ + 1 biais
- Une ou plusieurs couche de TLU appel√© *hidden layer* de taille {1,n}
- Une couche finale de TLU appel√©e *output layer*, a adapt√© suivant la probl√©matique de mod√©lisation

La couche cach√©e proche de l'intput layer est appel√©e couche basse et la couche cach√©e proche de l'output layer est appell√©e couche haute.

Chaque couche doit contenir un biais **sauf la couche de sortie**

Graphique N¬∞7 : Architecture d'un r√©seau de neurone multicouche

<img src="https://github.com/Roulitoo/cours_iae/blob/master/02_ANN/img/mlp_07.png" alt="07_MPL.png" style="width:600px;"/>

üí°
> Graphiquement on observe que tous les flux vont dans une unique direction. On parle ici de **feedforward neural network**.

> Quand un ANN contient plusieurs couches cach√©es on parle de **deep neural network**


### 3.1-Algorithme de r√©tropropagation du gradient
Pour entrainer ce type de mod√®le, on utilise une variante de la descente de gradient vue au premier cours.
On l'appelle la r√©tropropagation du gradient (backprogation gradient).

Sans le d√©finir math√©matiquement, le concept de r√©tropogation suit les √©tapes suivantes :

- **1)** S√©lectionner un mini-batch(sous ensemble de donn√©es) de taille = n qui passera par l'ensemble de notre train
<br>

- **2)** Chaque mini-batch passera par l'input layer jusqu'√† l'output layer pour r√©aliser une pr√©diction. Chaque instance du mini-batch passera. 
On conserve √©galement les r√©sultats interm√©diaires de chaque neurone.
<br>

- **3)** Avec notre fonction de perte on mesure l'√©cart entre notre pr√©diction et la valeur r√©elle
<br>

- **4)** L'algorithme calcule la contribution de la couche de sortie sur l'erreur calcul√©e ( En appliquant la d√©riv√©e des fonctions compos√©es)
<br>

- **5)** Ensuite on regarde la part contributive de quelle connexion avec la couche pr√©c√©dente produit l'erreur.(Toujours avec le principe de d√©riv√©e de fonctions compos√©es).
On remonte jusqu'√† la couche d'entr√©e avec ce proc√©d√©.
<br>

- **6)** Finalement, l'algorithme ajuste toutes les connexions en utilisant la descente de gradient pour ajuster les param√®tres

**En r√©sum√©:**<br>
L'algorithme r√©tropropagation du gradient calcule pour chaque instance d'un mini-batch une pr√©diction avec un forward pass et mesure l'erreur produite.<br>
En faisant chemin inverse, on mesure la contribution de chaque connexion dans l'erreur produite et enfin, on met √† jour les poids de connexion pour r√©duire l'erreur.<br>
[Si vouz voulez une vid√©o explicative cliquez ici](https://www.youtube.com/watch?v=OgSA7liZMXI&ab_channel=Science4All)

##### TIPS ‚ö†Ô∏è
Il est important **d'initialiser le poids de chaque connexion de mani√®re al√©atoire autrement l'entrainement du mod√®le va √©chouer**.<br>
Si tous les poids sont les m√™mes la r√©tropropagation du gradient affectera les poids de la m√™me mani√®re et l'erreur produite ne changera pas!


**Noter :**

Un point important pour l'utilisation de l'algorithme de *backpropagation du gradient*. **Les step function sont remplac√©es par une sigmoide.**
A ce stade on ne parlera plus de **step function** mais de **fonction d'activation**.

Ce changement provient essentiellement que la step function contient seulement des segments plats. Une valeur constante ne poss√®de pas de d√©riv√©e, il est donc impossible de calculer un gradient.

Les auteurs ont remplac√© la fonction d'activation par une sigmoide mais de nombreuses fonctions d'activations existent. Examinons les et regardons comment les choisirs.

### 3.2-Fonctions d'activations communes

La fonction logistique ou sigmoide est en forme de S et poss√®de une d√©riv√©e pour chaque point sur sa courbe.
C'est la m√™me fonction utilis√©e pour la r√©gression logistique.

$\normalsize sigmoide : \sigma(z) = \frac{1}{1+exp(-z)}$

La tangente hyperbolique est une variation de la fonction sigmoide. Elle poss√®de √©galement une forme en S mais prend ses valeurs dans l'intervalle [-1,1]. Cela tend √† produire des output de neurones centr√©s autour de  0, ce qui am√©liore la vitesse de calcul lors de la descente de gradient. 

$\normalsize Hyperbolic tangent : tanh(z) = 2\sigma(2z)-1$

La fonction ReLU est continue mais non diff√©rentiable en 0 (la d√©riv√©e en 0 est 0). 
Cependant elle offre la possibilit√© de calculer tr√®s rapidement le gradient. On l'utilise souvent comme fonction par d√©faut avant de tuner le mod√®le.<br>

$\normalsize Rectified Linear Unit : ReLU(z) = max(0,z)$

Graphique N¬∞8 : [Allure des fonctions d'activations communes](https://miro.medium.com/max/1200/1*ZafDv3VUm60Eh10OeJu1vw.png)

<img src="https://github.com/Roulitoo/cours_iae/blob/master/02_ANN/img/activation_functions_plot_08.png" alt="08_active_function.png" style="width:800px;"/>

### 3.3-MLP pour la r√©gression

Les r√©seaux de neurones peuvent √™tre utilis√©s pour **mod√©liser une probl√©matique quantitative**. 

Suivant le nombre de pr√©diction a r√©aliser, il faut choisir le bon nombre de neurones en sortie.
La pr√©diction d'une valeur, par exemple le prix d'un bien immobilier, il faudra un seul neurone en couche de sortie.

Pour la pr√©diction de coordonn√©es, par exemple rechercher le centre de coordonn√©e (x,y) dans une image. Il faudra pr√©dire  2 output donc 2 neurones dans la couche de sortie seront n√©cessaires.

**De mani√®re g√©n√©rale, il y aura autant de neurone en couche de sortie que de valeur √† pr√©dire**

**Tips**üí°<br>
G√©n√©ralement, lors de taches de r√©gression il ne faut pas utiliser de fonction d'activation pour les neurones de sorties.
On pr√©f√®re ne pas appliquer de transformation afin de laisser la plage de valeur libre.
  
Cependant, il peut √™tre utile dans certains cas de contraindre la plage des valeurs avec une fonction d'activation.<br>
Par exemple, **la pr√©diction du revenu d'un client qui ne peut √™tre n√©gatif**.<br>
Dans ce cas, il est possible d'utiliser la fonction $softplus(z) = log(1+exp(z))$ qui permet de borner les valeurs entre ]0,infi[.<br>
<br>
Pour la fonction de perte vous pouvez utiliser ce que vous avez l'habitude d'utiliser **MAE,RMSE, Huber Loss**

Tableau N¬∞1:  üí°Tips pour la r√©gression

| Hyperparam√®tre              | Tips sur les valeurs                                                      |
|-----------------------------|---------------------------------------------------------------------------|
| Input neurones              | Un par feature + le biais                                                 |
| Couche cach√©e               | G√©n√©ralement entre 1 et 5                                                 |
| Neurones par couche cach√©es | G√©n√©ralement entre 10 et 100                                              |
| Output neurones             | 1 par dimension √† pr√©dire                                                 |
| Fonction activation cach√©   | ReLU ou SELU                                                              |
| Fonction activation output  | Libre, ReLU, softplus(positive output),<br>logistic/tanh(variable born√©e) |
| Fonction de perte           | MSE, MAE, Huber(moins sensible outliers)                                  |

### 3.4-MLP pour la classification

Bien √©videmment, on peut utiliser les r√©seaux de neurones pour des probl√©matiques de classification.<br>
Si on souhaite r√©aliser une classification binaire, il suffit d'utiliser une fonction d'activation logistique dans l'output neurone.
En sortie, le neurone produira un r√©sultat entre 0 et 1 qui pourra √™tre interpr√©t√© comme une probabilit√© d'appartenance √† classe positive de la classification.

Globalement, le mod√®le MLP permet de traiter toutes les taches de classification :

- **Multilabel binary classification**, il suffit de mettre une couche de sortie avec 2 neurones contenant chacun une fonction d'activation logistique.<br>
<br>
 
- **Multiclass classification** pour les probl√©matiques de classification √† plusieurs classes ind√©pendantes √† pr√©dire. Type le jeu de donn√©es *MNIST* pour la pr√©diction de chiffre manuscrit.

> Quand vous pr√©disez des probabilit√©s en sortie. Les fonctions de pertes log loss et cross-entropy sont une bonne id√©e.

Tableau N¬∞2 : üí° Tips pour la classification
    
| Hyperparam√®tre           	| Classification binaire       	| Multilabel binary classification    	| Multiclass classification    	|
|--------------------------	|------------------------------	|------------------------------	|------------------------------	|
| Input neurons            	| Nombre de features + biais   	| Nombre de features + biais   	| Nombre de features + biais   	|
| Hidden layer             	| G√©n√©ralement entre 1 et 5    	| G√©n√©ralement entre 1 et 5    	| G√©n√©ralement entre 1 et 5    	|
| Neurons per hidden layer 	| G√©n√©ralement entre 10 et 100 	| G√©n√©ralement entre 10 et 100 	| G√©n√©ralement entre 10 et 100 	|
| output neurons           	| 1                            	| 1 par label                  	| 1 par classe                 	|
| Output layer activation  	| Logistic                     	| Logistic                     	| Softmax                      	|
| Loss function            	| Cross entropy                	| Cross entropy                	| Cross entropy                	|

## 4-MPL avec Keras et Tensorflow
![logo keras tensor](https://lesdieuxducode.com/images/blog/titleimages/keras-tensorflow-logo.jpg)

### 4.1-Tensorflow

TensorFlow est un outil open source d'apprentissage automatique d√©velopp√© par Google. Le code source a √©t√© ouvert le 9 novembre 2015 par Google et publi√© sous licence Apache(open source).<br>

Il poss√®de aujourd'hui des interfaces en **Python**, Julia et **R**.<br>

Tensorflow a √©t√© d√©velopp√© initialement pour √™tre une librairie facilitant la manipulation de tenseur (tableau √† N dimensions). Elle permet de r√©aliser des calculs num√©riques et l'apprentissage machine √† grande √©chelle en utilisant pleinement les CPU et GPU.<br>
Tensorflow(TF) est utilisable avec python en utilisant son API qui en arri√®re-plan traite les op√©rations math√©matiques en C++.

TF est un langage √† tr√®s basse abstraction et permet de d√©finir tr√®s finement l'architecture de ses r√©seaux de neurones mais il implique une tr√®s bonne ma√Ætrise de son langage et peut √™tre difficile √† prendre en main.<br>

C'est pourquoi on l'utilise souvent avec keras qui est √©galement une API permettant de faire du deep learning mais avec un langage plus simple √† utiliser.<br>

### 4.2-Keras

Keras a √©t√© d√©velopp√© par un ing√©nieur francais *Francois Chollet*. Son projet est tr√®s rapidement devenu la librairie la plus utilis√©e des r√©seaux de neurones car elle offre une fl√©xibilit√© et une facilit√© non disponible dans les autres frameworks.

Keras utilise d'ailleurs tensorflow en arri√®re-plan pour r√©aliser les calcules math√©matiques. 
Elle est g√©n√©ralement utilis√©e comme interface entre le code saisie par le data scientist et tensorflow en backend r√©alisant les calculs.

> Une alternative develop√©e par Facebook *Pytorch* est √©galement possible. Mais nous utiliserons Keras + Tensorflow ici

> Afin de vous entrainer et voir comment int√©ragir avec les hyperparam√®tres du r√©seau de neurones, vous pouvez utiliser **[tensorflow en mode sandbox](https://playground.tensorflow.org/)**
### 4.3-Comment utiliser Keras

**Mettre √† jour sa distribution Anaconda et installer tensorflow**

```python
!pip install tensorflow==2.11.0
```

```python
#Import tensorflow and keras
import tensorflow as tf
from tensorflow import keras
```

### 4.4-Classification avec Keras

Reprenons le jeu de donn√©es **MNIST** utilis√© pour le chapitre 1 SVM.<br>
L'application sera cette fois faite avec un r√©seau de neurones pour la classification.<br>

Ce type de mod√®le est d'ailleurs recommand√© pour les donn√©es non structur√©es.

Rappel :
C'est un jeu de donn√©es c√©l√®bre qui comprend 70 000 images de chiffre √©crit √† la main.

Le jeu de donn√©es dispo sous keras est repr√©sent√© en 28*28 pixels, il faut le transformer en array 1D et 784 features pour le passer dans un mod√®le.<br>


#### 4.4.1-Impl√©mentation avec keras

```python
#Get data from keras datasets
mnist = keras.datasets.mnist
#Train and test set
(X_train_full, y_train_full), (X_test, y_test) = mnist.load_data()

#Pas de validation set, d√©ja fait.
#On divise pas 255 pour ramener dans l'interval [0,1] et faciliter la descente de gradient
X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] /255.0
y_valid, y_train = y_train_full[:5000], y_train_full[5000:]
```

**Dimension de la table X_train**
```python 
X_train_full.shape
>>(60000, 28, 28)
```

**Cr√©er un mod√®le en utilisant l'API s√©quentiel**

```python
#D√©finir un model s√©quentiel
model = keras.models.Sequential()
#Ajouter les couches dans le mod√®le
model.add(keras.layers.Flatten(input_shape=[28, 28]))
model.add(keras.layers.Dense(300, activation="relu"))
model.add(keras.layers.Dense(100, activation="relu"))
#Couche de sortie, action softmax car multiclass
model.add(keras.layers.Dense(10, activation="softmax"))
```

**1-)** Def mod√®le <br>
<br>
La premi√®re ligne permet de cr√©er un mod√®le de r√©seau de neurones.<br>
Le *S√©quential* permet de cr√©er un mod√®le que nous allons d√©finir s√©quentiellement.<br>
<br>
**2-)** Ajouter des couches manuellement :
- layers.Flatten permet de changer la dimension des donn√©es pour l'int√©grer comme features
- layers.dense permet de cr√©er une couche de neurones avec un nombre de neurones et une fonction d'activation
- Il faut penser √† toujours bien d√©finir la couche de sortie en fonction de sa probl√©matique

Il existe des mani√®res alternatives pour coder avec keras. A la mani√®re de sklearn qui propose une **fonction *pipeline***, on peut 
imbriquer le code<br>
```python
model = keras.models.Sequential([
keras.layers.Flatten(input_shape=[28, 28]),
keras.layers.Dense(300, activation="relu"),
keras.layers.Dense(100, activation="relu"),
keras.layers.Dense(10, activation="softmax")
])

```

**Afficher la structure du mod√®le**

La module *summary* permet d'afficher le type de mod√®le utilis√© ainsi que ses param√®tres.<br>
```python 

model.summary() 

#Output
Model: "sequential_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_2 (Flatten)         (None, 784)               0         
                                                                 
 dense_5 (Dense)             (None, 300)               235500    
                                                                 
 dense_6 (Dense)             (None, 100)               30100     
                                                                 
 dense_7 (Dense)             (None, 10)                1010      
                                                                 
=================================================================
Total params: 266,610
Trainable params: 266,610
Non-trainable params: 0
_________________________________________________________________
```

**Remarque:** üí°

Un mod√®le bas√© sur les r√©seaux de neurones poss√®dent beaucoup **plus de** que des **mod√®les** de **machine learning** classique.<br>
Cela permet d'apprendre sur des sch√©mas de donn√©es plus complexes mais cela augmente aussi le risque **d'overfitting**.<br>

Tous les param√®tres du mod√®le sont disponibles dans 

```python
#Obtenir le poids pour les param√®tres et biais
w, biais = model.layers[1].get_weights()
#Print weights
print(w)
>>array([[ 0.02804729,  0.06513095,  0.06868796, ...,  0.07075047,
>>        -0.0200577 , -0.00675891],
>>       [-0.06487748,  0.03767272,  0.01864241, ...,  0.05238518,
>>         0.0088407 , -0.07322135],
>>       [ 0.06850776, -0.05723136,  0.03121593, ...,  0.04858249,
>>        -0.03271103,  0.06832977],...
#Format de sortie
print(w.shape)
>>(300,784)
```


**Remarque :** üí°<br>
Les poids sont initialis√©s √† d√©faut de fa√ßon al√©atoire. Si tous les poids sont initialis√©s √† 0 la mise √† jour des poids serait la m√™me pour chaque connexion<br>

Il est possible d'initialiser les poids avec des techniques plus sp√©cifiques que nous ne pr√©senterons pas ici mais vous pouvez creuser la question [ici](https://keras.io/api/layers/initializers/)

Pensez √† sp√©cifier la taille de votre input avec la fonction input_shape pour l'initialisation du mod√®le. Le nombre de poids d√©pend directement du nombre d'input! Keras le calculera automatiquement si vous ne le sp√©cifiez pas mais il peut se tromper. 

#### 4.4.2-Compiler le mod√®le

Une fois que le mod√®le est d√©fini, vous devez le compiler en d√©finissant la fonction de perte la/les m√©triques que vous souhaitez utiliser pour estimer la qualit√© de votre mod√®le.

Impl√©mentation en python:

```python
#D√©finir fonction de perte
model.compile(loss="sparse_categorical_crossentropy",
              optimizer="sgd",
              metrics=["accuracy"]
             )
```

**Loss**

Cross entropy pour la classification est une mesure qui provient de la th√©orie de l'information.

Equation N¬∞7 : Cross-entropy ou log loss <br>

$\normalsize H_p(q) = -\frac{1}{N}\sum_{i=0}^N y_i.log(p(y_i))+(1-y_i).log(1-p(y_i))$

o√π:

- $N:$ Taille de l'√©chantillon
- $y_i$ : [0,1] donn√©es binaire pour classification
- $p_i$ : probabilit√© du i√®me individu

> Une cross entropy proche de 0 signifie que le mod√®le classifie parfaitement nos donn√©es, √† l'inverse plus le mod√®le aura une cross entropy √©lev√©e plus le mod√®le sera mauvais.

> Pour calculer la cross entropy vous devez obtenir des probabilti√©s en couche de sortie! **ATTENTION** √† vos d'activations de sortie 

**optimizer**

Ici nous utilisons le *sgd* qui signifie *stochastic gradient descent*.<br>
Il existe beaucoup d'optimiser mais nous utiliserons le *sgd*. Retenez que c'est l'optimiser qui permet de faire la r√©tropropagation de gradient!
Le learning rate associ√© est √† 0.01, comme valeur par d√©faut.

#### 4.4.3-Entrainer et √©valuer le mod√®le

Comme pour sklearn, il suffit d'utiliser la fonction .fit sur nos donn√©es d'entrainement pour que le mod√®le s'entraine.

```python 
train_model = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))
#ou, si pas de data de validation, on peut sp√©cifier un split sur le % de donn√©es
train_model = model.fit(X_train, y_train, epochs=30,  validation_split=0.1)
```

> L'hyperparam√®tre *validation_data* est optionnel

Pour keras la verbosit√© du mod√®le est tr√®s int√©ressante car vous pouvez examiner la qualit√© de votre mod√®le durant l'entrainement.

Graphique N¬∞9 : Output keras

<img src="https://github.com/Roulitoo/cours_iae/blob/master/02_ANN/img/output_model_keras_09.png" alt="output_model_keras_09.png" style="width:600px;"/>


D√©finition dans le cadre des r√©seaux de neurones :

- **Sample** : C'est une observation de notre √©chantillon (une ligne)<br>
- **Batch size** : C'est un hyperparam√®tre du mod√®le qui contr√¥le le nombre d'observations utilis√©es par le mod√®le avant de mettre √† jour les poids.
> Habituellement on prend des valeurs de 32,64,128,256
- **Epoch** : C'est un hyerparam√®tre √† d√©finir pour sp√©cifier le nombre de fois o√π le mod√®le doit voir l'ensemble des donn√©es. 
> Habituellement, on prend des valeurs de 10,100,500,1000

La fonction .fit() retourne un historique de tout l'entrainement du mod√®le. Vous pouvez acc√®der √† tous les poids qui ont √©volu√© durant l'entrainement du mod√®le.

```python
#Param√®tre du mod√®le
train_model.params
#Dictionnaire mod√®le history
train_model.history.keys()
>>dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
```
`history.keys()`contient les mesures de la fonction de perte et des extras metrics √† chaque fin des epochs.
Cela permet de regarder le qualit√© du mod√®le et sur/sous apprentissage possible.


#### 4.4.4-Leaning curve keras

Pour tracer les learning curve, on peut directement s'appuyer sur l'output disponible dans `.history()`.

```python
#Import package
import pandas as pd
import matplotlib.pyplot as plt

#Data to pandas dataframe
pd.DataFrame(history.history).plot(figsize=(8, 5))
plt.grid(True)
plt.gca().set_ylim(0, 1) 
plt.show(    
```
On obtient le graphique suivant

Grapnique N¬∞10 : Learning curve mod√®le ANN en fonction des Epochs

<img src="https://github.com/Roulitoo/cours_iae/blob/master/02_ANN/img/learning_curve_keras_11.png.png" alt="learning_curve_keras_11.png.png" style="width:600px;"/>


# Comment validation curve

> Remarque d√©calage des donn√©es plot loss https://twitter.com/aureliengeron/status/1110839223878184960

**Evaluation du mod√®le out sample**

Pour finir d'√©valuer son mod√®le r√©aliser une √©valuation du mod√®le out sample avec la commande 
```python 
train_model.evaluate(x_test, y_test)
```
**Pr√©dire une nouvelle valeur**

```python
train_model.predict_classes(X_new)
```

Vous savez maintenant comment :

- D√©finir l'architecture d'un mod√®le de r√©seau de neurones pour la classification
- Entrainer le mod√®le
- L'√©valuer
- R√©aliser une pr√©diction

## 4.5-R√©gression avec Keras

L'architecture pour la r√©gression suit le m√™me principe que la classification.<br>
On peut toujours d√©finir le mod√®le avec l'API s√©quentiel ou alors utiliser l'API fonctionnelle pour des mod√®les plus complexes que nous verrons ci-dessous.<br>

Application avec le dataset *california housing* contenant des informations relatives au prix de vente d'une maison en californie.
Ici, on cherche √† pr√©dire le prix de vente en centaine de millier de dollars.<br>

```python
#Get package
#On peut toujours faire son pr√©-processing avec sklearn
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

#Get data
housing = fetch_california_housing()
#Train and holdout
X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)
#Train data and validation set
X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)
#Scaling features with different size
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_valid = scaler.transform(X_valid)
X_test = scaler.transform(X_test)
```

Pour la cr√©ation s√©quentielle du mod√®le il faut proc√©der comme pour la classification.<br>

Les **diff√©rences majeures** √† garder en t√™te est qu'il faut **seulement 1 neurone en sortie** (pr√©dire une seule valeur).<br>
Ne pas mettre de fonction d'activation dans *l'output layer* sauf si vous cherchez √† restreindre la valeur de sortie.<br>
Changer la fonction de perte du mod√®le (loss function)

**C'est parti!**

```python
#Initialisation du mod√®le
reg_model = keras.models.Sequential()
#Shape input, number of columns
reg_model.add(keras.layers.Input(shape=8))#input layer
reg_model.add(keras.layers.Dense(500, activation='relu'))#Hidden layer, 500 neurones
reg_model.add(keras.layers.Dense(1))#Output layer

#Compil model parameter
model.compile(loss="mean_squared_error", optimizer="sgd")
#Fit model
history = model.fit(X_train, y_train, epochs=20,validation_data=(X_valid, y_valid))
#Validation out sample
mse_test = model.evaluate(X_test, y_test)
# ATTENTION A BIEN FAIRE X[:k] et pas X[k]
X_new = X_test[:3] # pretend these are new instances
y_pred = model.predict(X_new)

```


D√©finir le mod√®le avec une approche s√©quentielle est tr√®s commune et r√©pond √† de nombreux usages.<br>
Cependant, il est parfois utile d'utiliser des mod√®les plus complexes pour r√©pondre √† un probl√®me.<br>
C'est pourquoi *KERAS* propose une mani√®re alternative pour d√©finir l'archiecture de son r√©seau de neurones avec une **API fonctionnelle**.

### 4.5.1-Wide And Deep neural model

Ce type de mod√®le se d√©finit de mani√®re non s√©quentielle car il n'est pas une suite directe de couche de neurones. Il poss√®de une architecture plus complexe.<br>
Il cherche √† allier les mod√®les dit *Wide* et *Deep*

On dit qu'un mod√®le est Wide s'il poss√®de beaucoup de neurones et peu de couche (neurones>500).
Les mod√®les wide s'adaptent tr√®s bien √† des donn√©es avec un pattern simple √† d√©tecter dans un ensemble de donn√©es de taille faible ou moyenne.

On dit qu'un mod√®le est deep s'il poss√®de beaucoup de couches cach√©es et peu de neurones. (hidden >3)
Les mod√®les deep se prettent mieux aux donn√©es avec des patterns complexes et des jeux de donn√©es relativement grand.

Graphique N¬∞11 : Wide and Deep neural model schema

<img src="https://github.com/Roulitoo/cours_iae/blob/master/02_ANN/img/wide_deep_10.png" alt="wide_deep_11.png" style="width:600px;"/>


Pour implementer ce type de mod√®le avec keras il faut maintenant utiliser l'API fonctionnelle.

```python 
#set seed
from numpy.random import seed
seed(1)
from tensorflow.random import set_seed
set_seed(2)

#Define first layer
input_ = keras.layers.Input(shape=X_train.shape[1:])
#Hidden layer
hidden1 = keras.layers.Dense(30, activation="relu")(input_)
hidden2 = keras.layers.Dense(30, activation="relu")(hidden1)
#Concat first layer and output hidden
concat = keras.layers.Concatenate()([input_, hidden2])
#Output layer
output = keras.layers.Dense(1)(concat)
#define model
model = keras.Model(inputs=[input_], outputs=[output])
 
```

```python 
model.compile(loss="mse", 
              optimizer=keras.optimizers.SGD(learning_rate=1e-3)
             )
```

```python 
history = model.fit(X_train, y_train, epochs=20,validation_data=(X_valid, y_valid))
```

Description de ce qu'il se passe dans le mod√®le:

- **1)** Cr√©er l'input layer en sp√©cifiant le nombre de neurones avec le nombre de features<br>
<br>
 
- **2)** Cr√©er un hidden layer avec 30 neurones et une fonction d'activation relu qui sera connect√© √† l'input
     Noter qu'on le d√©finit comme une fonction avec un argument (input_) c'est pour ca qu'on parle d'API fonctionelle<br>
<br>
 
- **3)** Cr√©er un second hidden layer avec la m√™me architecture<br>
<br>
 
- **4)** On concate les r√©sultats des couches cach√©es avec l'input neurone avant de passer dans la couche de sortie<br>
<br>
 
- **5)** Cr√©er l'ouput layer avec 1 seul neurone sans fonction d'activation<br>
<br>
 
- **6)** Enregistrer l'architecture dans un mod√®le

> Si vous voulez un exemple plus complet des r√©seaux de neurones, wide, deep et wide and deep regarder ce [notebook kaggle](https://www.kaggle.com/code/hkapoor/wide-vs-deep-vs-wide-deep-neural-networks)

## 5-Hyperparameter tuning

Comme pr√©ciser plus haut dans le cours les r√©seaux de neurones offrent une souplesse et une pr√©cision peu √©galer par les mod√®les de machine learning. Leur nombre de param√®tres permet d'approcher au plus pr√®s ce qu'on souhaite mod√©liser.

M√™me pour des structures assez simples comme le MLP vous pouvez tuner les hyperparam√®tres suivants :

- Nb de neurones par couche
- Nb de couches
- Fonction d'activation
- Learning rate
- L'initiliasation des poids 
- ...

De mani√®re g√©n√©rale, plus le **nombre d'hyperparam√®tres** √† tuner **augmentent** plus le risque d'**overfitting** est √©lev√©!

Une mani√®re simple de tuner votre mod√®le est d'utiliser la m√™me technique qu'en machine learning en d√©finissant vos hyperparam√®tres avec une plage de valeur (avec un gridsearch par exemple).

**Attention**‚ùó<br>
Les objets de **sklearn et keras ne communiquent pas nativement**. Ils ont des types diff√©rents.<br>
Pour utiliser un objet de keras avec sklearn, il faut utiliser un *wrapper* keras vers sklearn.<br>
La d√©marche est assez simple et keras poss√®de une fonction wrap pour communiquer avec d'autres API.

### Step 1 imbriquer keras dans une fonction

Il faut passer nos fonctions keras dans une unique fonction. Ici, nous cr√©ons un mod√®le que nous devons imbriquer enti√®rement dans une fonction.<br>

Exemple avec une fonction pour cr√©er un mod√®le permettant de faire une r√©gression avec un MLP avec en param√®tre √† passer le nombre de couches, neurones par couche, learning_rate et input_shape.

```python 
def build_model(n_hidden, n_neurons, lr,input_shape=[8]):
    #Define sequential model
    model = keras.models.Sequential()
    #Input shape
    model.add(keras.layers.InputLayer(input_shape=input_shape))
    #Add hidden layer with loop
    for layer in range(n_hidden):
        model.add(keras.layers.Dense(n_neurons, activation="relu"))
    #Ouput layer    
    model.add(keras.layers.Dense(1))
    #Define optimizer
    optimizer = keras.optimizers.SGD(learning_rate=lr)
    #Compile model
    model.compile(loss="mse", optimizer=optimizer)
    return(model)

```


### Step 2 wrap function

Il faut maintenant int√©grer notre fonction dans un wrapper pour utiliser la fonction de sklearn *gridsearchCV* avec un mod√®le provenant de keras.

```python
from scikeras.wrappers import KerasClassifier, KerasRegressor
keras_reg = KerasRegressor(build_model)
```

### Step 3 GridSearch et passage d'hyperparam√®tre

Pour passer les hyperparam√®tres de notre grille de param√®trage et notre *scikeras.wrappers*, il y a 2 solutions :

- Passage des param√®tres avec suffixe **model__** qui fait r√©f√©rence au mod√®le d√©finit par notre def fonction
- Passage des param√®tres √† travers la fonction KerasRegressor qui peut prendre en entr√©e des hyperparam√®tres

La solution avec suffixe √©tant plus lisible en mati√®re de code, nous allons l'√©xaminer.

```python
#Import fonction? 
from sklearn.model_selection import GridSearchCV #RandomizedSearchCV marche aussi
#Param√®tre grille, model__ en suffixe devant nos arguments de fonction def
param_distribs = {
"model__n_hidden": [1, 2, 3],
"model__n_neurons":[50,100,200],
"model__lr":  [0.0001, 0.001, 0.1]
}
#On peut aussi ajouter le nombre epochs : [30] dans la grille

#grid search
rnd_search_cv = GridSearchCV(keras_reg, param_distribs,cv=2)
#Fit model with grid search
rnd_search_cv.fit(X_train, y_train)

print(rnd_search_cv.best_params_, rnd_search_cv.best_score_)

```

Vous savez maintenant cr√©er un mod√®le avec keras et tensorflow en backend puis chercher les meilleurs hyperparam√®tres et apr√®s tuner votre mod√®le.


### Tips hyperparam√®tre ANN

##### Nombre de couches cach√©es

G√©n√©ralement il suffit de 1 ou 2 hidden layer pour traiter votre probl√®me. Il faut mieux utiliser peu de couche cach√©e et augmenter le nombre de neurones √† l'int√©rieur.
Si vous continuez √† avoir des performances faibles augmenter votre nombre de couches tant que vous n'√™tes pas en overfitting.

##### Nombre de neurones par couches cach√©es

Le nombre de neurones en input et output est fixe et d√©pend du nombre de features et du type de mod√©lisation.
G√©n√©ralement on utilise 2 types d'approches:

- Technique en pyramide, plus on avance dans les couches cach√©es plus on diminue le nombre de neurones par couche. Exemple pour 3 couches cach√©es 300 puis 200 puis 100.

- Actuellement, on fixe souvent le m√™me nombre de neurones sur chaque couche.

Globalement, Vous pouvez augmenter votre nombre de neurones tant que vous n'√™tes pas en overfitting

##### Learning rate

C'est probablement l'hyperparam√®tre le plus influent les mod√®les.
Una mani√®re de le choisir est de partir d'un niveau faible par exemple 1e-5 et monter jusqu'√† 1 par pas de *exp(log(ecart_dizaine)/nb_iteration)*. Ici cela nous donnerait un pas de exp(log(10^5)/500) 

Une fois que vous avez fait ca tracer l'√©volution de votre loss en fonction de l'√©volution du learning rate et vous verez le point optimal assez facilement.

##### Batch size

Dans la litt√©rature on retrouve un batch_size fix√© entre 2 et 192. Il faut tester
G√©n√©ralement la valeur par d√©faut est de 32.

##### Fonction activation

On utilise la fonction ReLU comme fonction d'activation par d√©faut car sa d√©riv√©e est simple √† calculer pour la descente de gradient. Vous pouvez la changer en fonction des performances de votre mod√®le.

Pour l'activation de la fonction output cela d√©pend de ce que vous voulez obtenir √† la fin

## Doc utile

- [Scikeras wrapper pour interaction keras et scikit-learn](https://www.adriangb.com/scikeras/refs/heads/master/index.html)
- [Kaggle wide and deep neural model](https://www.kaggle.com/code/hkapoor/wide-vs-deep-vs-wide-deep-neural-networks)
- [Surement le meilleur cours sur le deep learning](https://fr.coursera.org/specializations/deep-learning)
- [Cheat sheet architecture des mod√®les de r√©seaux de neurones](https://www.asimovinstitute.org/neural-network-zoo/)
- [Crit√®re de early stopping pour ANN](https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/)
- [Vid√©o Keras tuner](https://www.youtube.com/watch?v=Un0JDL3i5Hg&t=24s)
- [Batch normalization pour acc√©l√®rer vos r√©seaux de neurones](https://machinelearningmastery.com/how-to-accelerate-learning-of-deep-neural-networks-with-batch-normalization/)
